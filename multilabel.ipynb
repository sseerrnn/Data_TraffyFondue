{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup,AutoTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional.classification import accuracy,  multilabel_auroc as auroc\n",
    "from torchmetrics import F1Score as f1\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>type</th>\n",
       "      <th>comment</th>\n",
       "      <th>‡∏ñ‡∏ô‡∏ô</th>\n",
       "      <th>‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤</th>\n",
       "      <th>‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á</th>\n",
       "      <th>‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢</th>\n",
       "      <th>‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°</th>\n",
       "      <th>‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î</th>\n",
       "      <th>...</th>\n",
       "      <th>‡∏õ‡πâ‡∏≤‡∏¢</th>\n",
       "      <th>‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î</th>\n",
       "      <th>PM25</th>\n",
       "      <th>‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°</th>\n",
       "      <th>‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞</th>\n",
       "      <th>‡∏Ñ‡∏ô‡∏à‡∏£‡∏à‡∏±‡∏î</th>\n",
       "      <th>‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á</th>\n",
       "      <th>‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥</th>\n",
       "      <th>‡∏õ‡πâ‡∏≤‡∏¢‡∏à‡∏£‡∏≤‡∏à‡∏£</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-BEJ9PP</td>\n",
       "      <td>['‡∏ñ‡∏ô‡∏ô']</td>\n",
       "      <td>‡∏™‡∏∞‡∏û‡∏≤‡∏ô‡∏•‡∏≠‡∏¢‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤ ‡∏ñ‡∏ô‡∏ô‡πÄ‡∏•‡πá‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Ç‡πâ‡∏≤...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-DDF9VX</td>\n",
       "      <td>['‡∏Ñ‡∏•‡∏≠‡∏á', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢', '‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']</td>\n",
       "      <td>‡∏ü‡∏∏‡∏ï‡∏ö‡∏≤‡∏ó‡∏¢‡∏∏‡∏ö ‡πÅ‡∏•‡∏∞‡πÅ‡∏Ñ‡∏ö‡∏°‡∏≤‡∏Å ‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏û‡∏•‡∏±‡∏î‡∏ï‡∏Å‡∏•‡∏á‡∏Ñ‡∏•‡∏≠‡∏á‡∏ó‡∏µ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-8TN97P</td>\n",
       "      <td>['‡∏à‡∏£‡∏≤‡∏à‡∏£']</td>\n",
       "      <td>‡πÄ‡∏™‡∏≤‡πÑ‡∏ü‡∏à‡∏£‡∏≤‡∏à‡∏£‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏à‡∏∞‡∏•‡πâ‡∏°</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-GPUWCP</td>\n",
       "      <td>['‡∏™‡∏≤‡∏¢‡πÑ‡∏ü', '‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ']</td>\n",
       "      <td>‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏™‡∏π‡πâ‡∏ä‡∏ô‡∏™‡∏≤‡∏¢‡πÑ‡∏ü</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-KNYYC3</td>\n",
       "      <td>['‡∏Ñ‡∏•‡∏≠‡∏á', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î']</td>\n",
       "      <td>‡∏Å‡∏≤‡∏£‡∏ó‡∏¥‡πâ‡∏á‡∏Ç‡∏¢‡∏∞‡∏•‡∏á‡πÉ‡∏ô‡∏•‡∏≥‡∏Ñ‡∏•‡∏≠‡∏á</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207084</th>\n",
       "      <td>208671</td>\n",
       "      <td>2023-4989VN</td>\n",
       "      <td>['‡∏ñ‡∏ô‡∏ô', '‡∏Ñ‡∏•‡∏≠‡∏á']</td>\n",
       "      <td>üì¢üîäüå≥üçÉüéã‡πÅ‡∏à‡πâ‡∏á ‡∏°‡∏µ‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä ‡πÄ‡∏•‡∏∑‡πâ‡∏≠‡∏¢‡∏û‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡πÑ‡∏ï‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏π...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207085</th>\n",
       "      <td>208672</td>\n",
       "      <td>UNWWLC</td>\n",
       "      <td>['‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô', '‡∏ñ‡∏ô‡∏ô']</td>\n",
       "      <td>‚Äò‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡∏Å‡∏´‡∏°‡∏∏‡∏î‚Äô\\n* ‡∏õ‡∏±‡∏ç...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207086</th>\n",
       "      <td>208673</td>\n",
       "      <td>PT24KT</td>\n",
       "      <td>['‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î']</td>\n",
       "      <td>‡∏õ‡∏±‡∏ç‡∏´‡∏≤ : ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏ô‡∏Å‡∏û‡∏¥‡∏£‡∏≤‡∏ö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å\\n‡∏à‡∏∏‡∏î‡∏™‡∏±‡∏á‡πÄ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207087</th>\n",
       "      <td>208674</td>\n",
       "      <td>2023-GL4KWC</td>\n",
       "      <td>['‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']</td>\n",
       "      <td>‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏™‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏•‡∏¢ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏î‡∏¢‡∏î‡πà‡∏ß‡∏ô</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207088</th>\n",
       "      <td>208675</td>\n",
       "      <td>2023-3VZH9L</td>\n",
       "      <td>['‡∏ñ‡∏ô‡∏ô', '‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ', '‡∏à‡∏£‡∏≤‡∏à‡∏£']</td>\n",
       "      <td>‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ö‡∏±‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÑ‡∏ü‡∏à‡∏£‡∏≤‡∏à‡∏£ ‡∏ñ‡∏ô‡∏ô‡∏ß‡∏£‡∏à‡∏±‡∏Å‡∏£ ‡πÅ‡∏¢‡∏Å‡∏ß‡∏£‡∏à‡∏±‡∏Å‡∏£ ‡∏°‡∏∏‡πà...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207089 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    ticket_id                                type  \\\n",
       "0                0  2021-BEJ9PP                             ['‡∏ñ‡∏ô‡∏ô']   \n",
       "1                1  2021-DDF9VX  ['‡∏Ñ‡∏•‡∏≠‡∏á', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢', '‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']   \n",
       "2                2  2022-8TN97P                           ['‡∏à‡∏£‡∏≤‡∏à‡∏£']   \n",
       "3                3  2022-GPUWCP                 ['‡∏™‡∏≤‡∏¢‡πÑ‡∏ü', '‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ']   \n",
       "4                4  2022-KNYYC3               ['‡∏Ñ‡∏•‡∏≠‡∏á', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î']   \n",
       "...            ...          ...                                 ...   \n",
       "207084      208671  2023-4989VN                     ['‡∏ñ‡∏ô‡∏ô', '‡∏Ñ‡∏•‡∏≠‡∏á']   \n",
       "207085      208672       UNWWLC               ['‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô', '‡∏ñ‡∏ô‡∏ô']   \n",
       "207086      208673       PT24KT                      ['‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î']   \n",
       "207087      208674  2023-GL4KWC                         ['‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']   \n",
       "207088      208675  2023-3VZH9L          ['‡∏ñ‡∏ô‡∏ô', '‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ', '‡∏à‡∏£‡∏≤‡∏à‡∏£']   \n",
       "\n",
       "                                                  comment  ‡∏ñ‡∏ô‡∏ô  ‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤  \\\n",
       "0       ‡∏™‡∏∞‡∏û‡∏≤‡∏ô‡∏•‡∏≠‡∏¢‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤ ‡∏ñ‡∏ô‡∏ô‡πÄ‡∏•‡πá‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Ç‡πâ‡∏≤...    1        0   \n",
       "1       ‡∏ü‡∏∏‡∏ï‡∏ö‡∏≤‡∏ó‡∏¢‡∏∏‡∏ö ‡πÅ‡∏•‡∏∞‡πÅ‡∏Ñ‡∏ö‡∏°‡∏≤‡∏Å ‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏û‡∏•‡∏±‡∏î‡∏ï‡∏Å‡∏•‡∏á‡∏Ñ‡∏•‡∏≠‡∏á‡∏ó‡∏µ...    0        1   \n",
       "2                                    ‡πÄ‡∏™‡∏≤‡πÑ‡∏ü‡∏à‡∏£‡∏≤‡∏à‡∏£‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏à‡∏∞‡∏•‡πâ‡∏°    0        0   \n",
       "3                                        ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏™‡∏π‡πâ‡∏ä‡∏ô‡∏™‡∏≤‡∏¢‡πÑ‡∏ü    0        0   \n",
       "4                                    ‡∏Å‡∏≤‡∏£‡∏ó‡∏¥‡πâ‡∏á‡∏Ç‡∏¢‡∏∞‡∏•‡∏á‡πÉ‡∏ô‡∏•‡∏≥‡∏Ñ‡∏•‡∏≠‡∏á    0        0   \n",
       "...                                                   ...  ...      ...   \n",
       "207084  üì¢üîäüå≥üçÉüéã‡πÅ‡∏à‡πâ‡∏á ‡∏°‡∏µ‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä ‡πÄ‡∏•‡∏∑‡πâ‡∏≠‡∏¢‡∏û‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡πÑ‡∏ï‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏π...    1        0   \n",
       "207085  ‚Äò‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡∏Å‡∏´‡∏°‡∏∏‡∏î‚Äô\\n* ‡∏õ‡∏±‡∏ç...    1        0   \n",
       "207086  ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ : ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏ô‡∏Å‡∏û‡∏¥‡∏£‡∏≤‡∏ö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å\\n‡∏à‡∏∏‡∏î‡∏™‡∏±‡∏á‡πÄ...    0        0   \n",
       "207087     ‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏™‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏•‡∏¢ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏î‡∏¢‡∏î‡πà‡∏ß‡∏ô    0        1   \n",
       "207088  ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ö‡∏±‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÑ‡∏ü‡∏à‡∏£‡∏≤‡∏à‡∏£ ‡∏ñ‡∏ô‡∏ô‡∏ß‡∏£‡∏à‡∏±‡∏Å‡∏£ ‡πÅ‡∏¢‡∏Å‡∏ß‡∏£‡∏à‡∏±‡∏Å‡∏£ ‡∏°‡∏∏‡πà...    1        0   \n",
       "\n",
       "        ‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢  ‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î  ...  ‡∏õ‡πâ‡∏≤‡∏¢  ‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î  \\\n",
       "0              0            0        0          0  ...     0           0   \n",
       "1              0            1        0          0  ...     0           0   \n",
       "2              0            0        0          0  ...     0           0   \n",
       "3              0            0        0          0  ...     0           0   \n",
       "4              0            0        0          1  ...     0           0   \n",
       "...          ...          ...      ...        ...  ...   ...         ...   \n",
       "207084         0            0        0          0  ...     0           0   \n",
       "207085         0            0        0          0  ...     0           0   \n",
       "207086         0            0        0          0  ...     0           1   \n",
       "207087         0            0        0          0  ...     0           0   \n",
       "207088         0            0        0          0  ...     0           0   \n",
       "\n",
       "        PM25  ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°  ‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞  ‡∏Ñ‡∏ô‡∏à‡∏£‡∏à‡∏±‡∏î  ‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á  ‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥  ‡∏õ‡πâ‡∏≤‡∏¢‡∏à‡∏£‡∏≤‡∏à‡∏£  \\\n",
       "0          0       0        0        0           0        0          0   \n",
       "1          0       0        0        0           0        0          0   \n",
       "2          0       0        0        0           0        0          0   \n",
       "3          0       0        0        0           0        0          0   \n",
       "4          0       0        0        0           0        0          0   \n",
       "...      ...     ...      ...      ...         ...      ...        ...   \n",
       "207084     0       0        0        0           0        0          0   \n",
       "207085     0       0        0        0           0        0          0   \n",
       "207086     0       0        0        0           0        0          0   \n",
       "207087     0       0        0        0           0        0          0   \n",
       "207088     0       0        0        0           0        0          0   \n",
       "\n",
       "                                                   labels  \n",
       "0       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "207084  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "207085  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "207086  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "207087  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "207088  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, ...  \n",
       "\n",
       "[207089 rows x 29 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv',index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>type</th>\n",
       "      <th>comment</th>\n",
       "      <th>‡∏ñ‡∏ô‡∏ô</th>\n",
       "      <th>‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤</th>\n",
       "      <th>‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á</th>\n",
       "      <th>‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢</th>\n",
       "      <th>‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°</th>\n",
       "      <th>‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î</th>\n",
       "      <th>‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á</th>\n",
       "      <th>...</th>\n",
       "      <th>‡∏õ‡πâ‡∏≤‡∏¢</th>\n",
       "      <th>‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î</th>\n",
       "      <th>PM25</th>\n",
       "      <th>‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°</th>\n",
       "      <th>‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞</th>\n",
       "      <th>‡∏Ñ‡∏ô‡∏à‡∏£‡∏à‡∏±‡∏î</th>\n",
       "      <th>‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á</th>\n",
       "      <th>‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥</th>\n",
       "      <th>‡∏õ‡πâ‡∏≤‡∏¢‡∏à‡∏£‡∏≤‡∏à‡∏£</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141823</th>\n",
       "      <td>2022-FXCB7Q</td>\n",
       "      <td>['‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á']</td>\n",
       "      <td>‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏£‡∏¥‡∏°‡∏Ñ‡∏•‡∏≠‡∏á‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏õ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116002</th>\n",
       "      <td>2022-CYKPR6</td>\n",
       "      <td>['‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']</td>\n",
       "      <td>‡∏™‡∏¥‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ ‡∏ó‡∏±‡πâ‡∏á‡∏ü‡∏∏‡∏ï‡∏ö‡∏≤‡∏ó‡πÅ‡∏•‡∏∞‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33014</th>\n",
       "      <td>2022-DE97ZE</td>\n",
       "      <td>['‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']</td>\n",
       "      <td>‡∏û‡∏∑‡πâ‡∏ô‡∏ü‡∏∏‡∏ï‡∏ö‡∏≤‡∏ó‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì BTS ‡∏ö‡∏≤‡∏á‡∏´‡∏ß‡πâ‡∏≤ ‡∏ó‡∏≤‡∏á‡∏≠‡∏≠‡∏Å 1 ‡πÅ‡∏•‡∏∞ 2 ‡∏°‡∏µ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137818</th>\n",
       "      <td>2022-797GPT</td>\n",
       "      <td>['‡∏™‡∏≤‡∏¢‡πÑ‡∏ü']</td>\n",
       "      <td>‡∏™‡∏≤‡∏¢‡πÑ‡∏ü‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏•‡∏á‡∏°‡∏≤‡∏Ç‡∏ß‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10817</th>\n",
       "      <td>2022-38AZNZ</td>\n",
       "      <td>['‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°']</td>\n",
       "      <td>‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°‡∏™‡∏π‡∏á</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42029</th>\n",
       "      <td>FRLKLZ</td>\n",
       "      <td>['‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î']</td>\n",
       "      <td>‡∏´‡∏°‡∏≤‡πÄ‡∏´‡πà‡∏≤ ‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏´‡∏°‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏Ç‡∏µ‡πâ‡∏´‡∏°‡∏≤‡πÇ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134861</th>\n",
       "      <td>2022-8R6YEF</td>\n",
       "      <td>['‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î']</td>\n",
       "      <td>‡∏ó‡∏≥‡∏´‡∏°‡∏±‡∏ô‡πÅ‡∏°‡∏ß‡∏à‡∏£</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132833</th>\n",
       "      <td>2022-GCBHEU</td>\n",
       "      <td>['‡∏™‡∏∞‡∏û‡∏≤‡∏ô', '‡∏Ñ‡∏•‡∏≠‡∏á']</td>\n",
       "      <td>‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏™‡∏∞‡∏û‡∏≤‡∏ô‡πÅ‡∏´‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡∏∞‡∏û‡∏≤...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53967</th>\n",
       "      <td>2022-C6FLH8</td>\n",
       "      <td>['‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô']</td>\n",
       "      <td>‡πÅ‡∏Ñ‡∏°‡∏õ‡πå‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏≤ (‡πÄ‡∏ä‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏ã‡∏≠‡∏¢‡∏ñ‡∏±‡∏î‡∏à‡∏≤‡∏Å...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142404</th>\n",
       "      <td>2023-9P4AE2</td>\n",
       "      <td>['‡∏õ‡πâ‡∏≤‡∏¢']</td>\n",
       "      <td>‡∏õ‡πâ‡∏≤‡∏¢‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ö‡∏î‡∏ö‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏Ç‡∏ì‡∏∞‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ã...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ticket_id               type  \\\n",
       "141823  2022-FXCB7Q       ['‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á']   \n",
       "116002  2022-CYKPR6        ['‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']   \n",
       "33014   2022-DE97ZE        ['‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤']   \n",
       "137818  2022-797GPT          ['‡∏™‡∏≤‡∏¢‡πÑ‡∏ü']   \n",
       "10817   2022-38AZNZ        ['‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°']   \n",
       "...             ...                ...   \n",
       "42029        FRLKLZ     ['‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î']   \n",
       "134861  2022-8R6YEF     ['‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î']   \n",
       "132833  2022-GCBHEU  ['‡∏™‡∏∞‡∏û‡∏≤‡∏ô', '‡∏Ñ‡∏•‡∏≠‡∏á']   \n",
       "53967   2022-C6FLH8     ['‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô']   \n",
       "142404  2023-9P4AE2           ['‡∏õ‡πâ‡∏≤‡∏¢']   \n",
       "\n",
       "                                                  comment  ‡∏ñ‡∏ô‡∏ô  ‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤  \\\n",
       "141823  ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏£‡∏¥‡∏°‡∏Ñ‡∏•‡∏≠‡∏á‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏õ...    0        0   \n",
       "116002   ‡∏™‡∏¥‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ ‡∏ó‡∏±‡πâ‡∏á‡∏ü‡∏∏‡∏ï‡∏ö‡∏≤‡∏ó‡πÅ‡∏•‡∏∞‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á    0        1   \n",
       "33014   ‡∏û‡∏∑‡πâ‡∏ô‡∏ü‡∏∏‡∏ï‡∏ö‡∏≤‡∏ó‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì BTS ‡∏ö‡∏≤‡∏á‡∏´‡∏ß‡πâ‡∏≤ ‡∏ó‡∏≤‡∏á‡∏≠‡∏≠‡∏Å 1 ‡πÅ‡∏•‡∏∞ 2 ‡∏°‡∏µ...    0        1   \n",
       "137818                  ‡∏™‡∏≤‡∏¢‡πÑ‡∏ü‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏•‡∏á‡∏°‡∏≤‡∏Ç‡∏ß‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏ó‡πâ‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö    0        0   \n",
       "10817                                          ‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°‡∏™‡∏π‡∏á    0        0   \n",
       "...                                                   ...  ...      ...   \n",
       "42029   ‡∏´‡∏°‡∏≤‡πÄ‡∏´‡πà‡∏≤ ‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏´‡∏°‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏Ç‡∏µ‡πâ‡∏´‡∏°‡∏≤‡πÇ...    0        0   \n",
       "134861                                        ‡∏ó‡∏≥‡∏´‡∏°‡∏±‡∏ô‡πÅ‡∏°‡∏ß‡∏à‡∏£    0        0   \n",
       "132833  ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏™‡∏∞‡∏û‡∏≤‡∏ô‡πÅ‡∏´‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡∏∞‡∏û‡∏≤...    0        0   \n",
       "53967   ‡πÅ‡∏Ñ‡∏°‡∏õ‡πå‡∏Ñ‡∏ô‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏≤ (‡πÄ‡∏ä‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏ã‡∏≠‡∏¢‡∏ñ‡∏±‡∏î‡∏à‡∏≤‡∏Å...    0        0   \n",
       "142404  ‡∏õ‡πâ‡∏≤‡∏¢‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ö‡∏î‡∏ö‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏Ç‡∏ì‡∏∞‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ã...    0        0   \n",
       "\n",
       "        ‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢  ‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î  ‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á  ...  ‡∏õ‡πâ‡∏≤‡∏¢  \\\n",
       "141823         1            0        0          0        0  ...     0   \n",
       "116002         0            0        0          0        0  ...     0   \n",
       "33014          0            0        0          0        0  ...     0   \n",
       "137818         0            0        0          0        0  ...     0   \n",
       "10817          0            0        1          0        0  ...     0   \n",
       "...          ...          ...      ...        ...      ...  ...   ...   \n",
       "42029          0            0        0          0        0  ...     0   \n",
       "134861         0            0        0          0        0  ...     0   \n",
       "132833         0            0        0          0        0  ...     0   \n",
       "53967          0            0        0          0        0  ...     0   \n",
       "142404         0            0        0          0        0  ...     1   \n",
       "\n",
       "        ‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î  PM25  ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°  ‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞  ‡∏Ñ‡∏ô‡∏à‡∏£‡∏à‡∏±‡∏î  ‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á  ‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥  \\\n",
       "141823           0     0       0        0        0           0        0   \n",
       "116002           0     0       0        0        0           0        0   \n",
       "33014            0     0       0        0        0           0        0   \n",
       "137818           0     0       0        0        0           0        0   \n",
       "10817            0     0       0        0        0           0        0   \n",
       "...            ...   ...     ...      ...      ...         ...      ...   \n",
       "42029            1     0       0        0        0           0        0   \n",
       "134861           1     0       0        0        0           0        0   \n",
       "132833           0     0       0        0        0           0        0   \n",
       "53967            0     0       0        0        0           0        0   \n",
       "142404           0     0       0        0        0           0        0   \n",
       "\n",
       "        ‡∏õ‡πâ‡∏≤‡∏¢‡∏à‡∏£‡∏≤‡∏à‡∏£                                             labels  \n",
       "141823          0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "116002          0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "33014           0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "137818          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "10817           0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...           ...                                                ...  \n",
       "42029           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "134861          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "132833          0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "53967           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "142404          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190, 28), (10, 28))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.05)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['‡∏ñ‡∏ô‡∏ô','‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤','‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á','‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢','‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°','‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î','‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á',\n",
    "        '‡∏ó‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏≤‡∏¢‡∏ô‡πâ‡∏≥','‡∏™‡∏∞‡∏û‡∏≤‡∏ô','‡∏à‡∏£‡∏≤‡∏à‡∏£','‡∏™‡∏≤‡∏¢‡πÑ‡∏ü','‡∏Ñ‡∏•‡∏≠‡∏á','‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô','‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ','‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô',\n",
    "        '‡∏õ‡πâ‡∏≤‡∏¢','‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î',\"PM25\",'‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°','‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞','‡∏Ñ‡∏ô‡∏à‡∏£‡∏à‡∏±‡∏î','‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á','‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥','‡∏õ‡πâ‡∏≤‡∏¢‡∏à‡∏£‡∏≤‡∏à‡∏£']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ‡∏ó‡∏≤‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ú‡∏π‡πâ‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô ‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ß‡∏¥‡∏Å‡∏≤‡∏•‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏•‡∏á‡∏ó‡∏≥‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏ß‡∏ñ‡∏ô‡∏ô ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏ñ‡∏™‡∏±‡∏ç‡∏à‡∏£‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏ó‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏¢‡∏≤‡∏°‡∏ß‡∏¥‡∏Å‡∏≤‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏Å‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏à‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏•‡∏≤‡∏¢‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡πÄ‡∏•‡∏¢ ‡∏£‡∏π‡πâ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏ó‡∏ô‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà 23:00-04:00 ‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡πÅ‡∏¢‡πà ‡∏ô‡∏≠‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\n",
      "\n",
      "{'‡∏ñ‡∏ô‡∏ô': 1, '‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡πâ‡∏≤': 0, '‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á': 0, '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢': 0, '‡∏ô‡πâ‡∏≥‡∏ó‡πà‡∏ß‡∏°': 0, '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î': 0, '‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á': 0, '‡∏ó‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏≤‡∏¢‡∏ô‡πâ‡∏≥': 0, '‡∏™‡∏∞‡∏û‡∏≤‡∏ô': 0, '‡∏à‡∏£‡∏≤‡∏à‡∏£': 0, '‡∏™‡∏≤‡∏¢‡πÑ‡∏ü': 0, '‡∏Ñ‡∏•‡∏≠‡∏á': 0, '‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô': 0, '‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ': 0, '‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô': 0, '‡∏õ‡πâ‡∏≤‡∏¢': 0, '‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏à‡∏£‡∏à‡∏±‡∏î': 0, 'PM25': 0, '‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°': 0, '‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞': 0, '‡∏Ñ‡∏ô‡∏à‡∏£‡∏à‡∏±‡∏î': 0, '‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á': 0, '‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥': 0, '‡∏õ‡πâ‡∏≤‡∏¢‡∏à‡∏£‡∏≤‡∏à‡∏£': 0}\n"
     ]
    }
   ],
   "source": [
    "sample_row = df.iloc[16]\n",
    "sample_comment = sample_row.comment\n",
    "sample_labels = sample_row[types]\n",
    "print(sample_comment)\n",
    "print()\n",
    "print(sample_labels.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_comment,\n",
    "  add_special_tokens=True,\n",
    "  max_length=512,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[\"input_ids\"].shape, encoding[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    5,  3428,    10,    75,   498,    10,  1591,    26,   966,   156,\n",
       "         4426,    10,  8580,  2346,   991,  8684, 13249,   553,   372,  2799])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[\"input_ids\"].squeeze()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[\"attention_mask\"].squeeze()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '‚ñÅ1.', '‚ñÅ', '‡∏ó‡∏≤‡∏á', '‡∏û‡∏¥‡πÄ‡∏®‡∏©', '‚ñÅ', '‡∏°‡∏±‡∏Å‡∏à‡∏∞', '‡∏°‡∏≤', '‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á', '‡πÄ‡∏ß‡∏•‡∏≤', '‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô', '‚ñÅ', '‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏ú‡∏π‡πâ', '‡∏≠‡∏≤‡∏®‡∏±‡∏¢', '‡πÉ‡∏Å‡∏•‡πâ', '‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô', '‚ñÅ‡∏ö‡∏≤‡∏á', '‡∏Å‡∏£‡∏ì‡∏µ', '‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°', '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentsDataset(Dataset):\n",
    "  def __init__(\n",
    "    self,\n",
    "    data: pd.DataFrame,\n",
    "    tokenizer: BertTokenizer,\n",
    "    max_token_len: int = 128\n",
    "  ):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.max_token_len = max_token_len\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, index: int):\n",
    "    data_row = self.data.iloc[index]\n",
    "    comment_text = data_row.comment\n",
    "    labels = data_row[types]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      comment_text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_token_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return dict(\n",
    "      comment_text=comment_text,\n",
    "      input_ids=encoding[\"input_ids\"].flatten(),\n",
    "      attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "      labels=torch.FloatTensor(labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['comment_text', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ToxicCommentsDataset(\n",
    "  train_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertModel: ['roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'lm_head.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.key.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'embeddings.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('airesearch/wangchanberta-base-att-spm-uncased', return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512]), torch.Size([8, 512]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(DataLoader(train_dataset, batch_size=8)))\n",
    "sample_batch[\"input_ids\"].shape, sample_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert_model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-4.4773e-01, -1.4829e-01,  6.1274e-01,  ...,  9.1935e-01,\n",
       "          -7.1762e-01,  9.9752e-01],\n",
       "         [-6.0689e-01,  6.2310e-01, -2.8681e-01,  ...,  4.2197e-01,\n",
       "           1.0650e-01,  1.2796e-01],\n",
       "         [-1.3682e-01, -1.1065e-01,  5.5573e-01,  ...,  4.7925e-01,\n",
       "          -1.5548e+00,  7.7126e-02],\n",
       "         ...,\n",
       "         [-7.7735e-01, -5.0141e-01,  9.9476e-01,  ...,  8.7856e-01,\n",
       "          -1.3373e+00, -3.3711e-01],\n",
       "         [-2.0743e-01, -1.2167e+00,  2.0887e-01,  ...,  1.1238e+00,\n",
       "          -1.6144e-01,  2.8420e-01],\n",
       "         [-5.7101e-01,  2.9514e-01,  1.0388e+00,  ...,  1.2022e+00,\n",
       "          -3.2453e-01,  1.0080e+00]],\n",
       "\n",
       "        [[-2.0190e-01,  6.4062e-02,  8.2502e-01,  ...,  7.8077e-01,\n",
       "          -8.4780e-01,  1.3088e+00],\n",
       "         [-6.4470e-01, -1.6259e-01,  1.1300e+00,  ..., -6.5792e-01,\n",
       "          -5.8097e-01, -1.6095e-01],\n",
       "         [-6.1005e-01,  5.6509e-01, -1.6551e-01,  ...,  1.5095e-01,\n",
       "          -7.6740e-01,  3.8621e-01],\n",
       "         ...,\n",
       "         [-5.8208e-01, -2.4846e-01,  1.1034e+00,  ...,  5.6253e-01,\n",
       "          -1.2368e+00, -2.2020e-01],\n",
       "         [-9.4471e-02, -1.1998e+00,  4.9911e-01,  ...,  9.6057e-01,\n",
       "          -2.3134e-01,  3.3674e-01],\n",
       "         [-5.0717e-01,  3.9771e-01,  1.2118e+00,  ...,  1.0740e+00,\n",
       "          -3.9970e-01,  1.2314e+00]],\n",
       "\n",
       "        [[-4.3883e-01, -1.1240e-01,  9.9628e-01,  ...,  5.9842e-01,\n",
       "          -8.3608e-01,  1.5717e+00],\n",
       "         [-6.6768e-01, -5.1456e-01,  9.4735e-02,  ..., -3.6343e-01,\n",
       "          -7.1242e-01,  6.4089e-01],\n",
       "         [-1.7162e+00, -4.8493e-01,  8.4774e-01,  ...,  3.6495e-01,\n",
       "          -1.2123e+00,  3.8375e-02],\n",
       "         ...,\n",
       "         [-8.5438e-01, -7.4065e-01,  1.3936e+00,  ...,  4.3202e-01,\n",
       "          -1.4130e+00,  2.8303e-02],\n",
       "         [-3.6961e-01, -1.6660e+00,  7.0080e-01,  ...,  9.1225e-01,\n",
       "          -3.1996e-01,  6.8187e-01],\n",
       "         [-7.2653e-01,  7.2654e-02,  1.3957e+00,  ...,  1.0968e+00,\n",
       "          -5.2920e-01,  1.4952e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.0954e-02,  2.7723e-02,  7.7238e-01,  ...,  6.1038e-01,\n",
       "          -1.0029e+00,  1.2584e+00],\n",
       "         [-6.1340e-01,  5.6018e-01, -4.6007e-01,  ...,  9.1139e-02,\n",
       "           5.2630e-02,  1.9018e-01],\n",
       "         [-7.6380e-01,  5.9616e-01,  2.5290e-01,  ..., -7.4634e-01,\n",
       "          -1.6303e+00, -3.4873e-01],\n",
       "         ...,\n",
       "         [-4.9105e-01, -2.3602e-01,  1.0829e+00,  ...,  4.3455e-01,\n",
       "          -1.4063e+00, -1.9178e-01],\n",
       "         [-5.7962e-02, -1.1608e+00,  4.7894e-01,  ...,  8.2859e-01,\n",
       "          -2.7079e-01,  4.0061e-01],\n",
       "         [-3.8253e-01,  4.3312e-01,  1.1809e+00,  ...,  8.9059e-01,\n",
       "          -5.1159e-01,  1.2031e+00]],\n",
       "\n",
       "        [[-3.0160e-02,  1.7450e-01,  9.3588e-01,  ...,  7.1037e-01,\n",
       "          -1.0695e+00,  1.3040e+00],\n",
       "         [-5.4239e-01,  7.2720e-01, -3.0598e-01,  ...,  2.2500e-01,\n",
       "          -4.1739e-02,  1.6695e-01],\n",
       "         [-3.6694e-01,  4.4957e-01, -2.3237e-01,  ..., -4.7029e-01,\n",
       "          -1.6552e+00,  5.9364e-01],\n",
       "         ...,\n",
       "         [-4.2986e-01, -1.1421e-01,  1.2600e+00,  ...,  4.6156e-01,\n",
       "          -1.4494e+00, -1.9195e-01],\n",
       "         [ 5.3695e-02, -1.1270e+00,  5.6809e-01,  ...,  9.4141e-01,\n",
       "          -3.8916e-01,  3.8981e-01],\n",
       "         [-3.7663e-01,  5.7688e-01,  1.3069e+00,  ...,  9.9599e-01,\n",
       "          -5.8015e-01,  1.2242e+00]],\n",
       "\n",
       "        [[-2.4469e-02,  4.2494e-02,  8.1501e-01,  ...,  6.0950e-01,\n",
       "          -8.6198e-01,  1.4103e+00],\n",
       "         [-5.4749e-01, -2.6026e-01, -7.3200e-02,  ...,  1.5836e-01,\n",
       "           2.7717e-01,  8.4869e-02],\n",
       "         [ 1.3458e-01,  2.4616e-01,  2.9910e-01,  ..., -5.2296e-01,\n",
       "          -1.7718e+00, -3.9721e-01],\n",
       "         ...,\n",
       "         [-5.2884e-01, -1.7932e-01,  1.1064e+00,  ...,  3.0243e-01,\n",
       "          -1.2243e+00, -3.5652e-02],\n",
       "         [-1.6992e-04, -1.2722e+00,  5.0532e-01,  ...,  7.6623e-01,\n",
       "          -2.0820e-01,  4.6767e-01],\n",
       "         [-4.1665e-01,  4.6809e-01,  1.1660e+00,  ...,  8.6927e-01,\n",
       "          -3.9411e-01,  1.3002e+00]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.4783,  0.0880,  0.8048,  ..., -0.3430, -0.6914, -0.7355],\n",
       "        [ 0.4453,  0.2423,  0.7028,  ..., -0.4869, -0.5859, -0.7163],\n",
       "        [ 0.5867,  0.1149,  0.6506,  ..., -0.4408, -0.6565, -0.7936],\n",
       "        ...,\n",
       "        [ 0.3668,  0.2563,  0.6662,  ..., -0.4713, -0.5095, -0.7273],\n",
       "        [ 0.4063,  0.1831,  0.6940,  ..., -0.4552, -0.5084, -0.7241],\n",
       "        [ 0.4288,  0.1972,  0.6727,  ..., -0.4675, -0.5896, -0.6869]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512, 768]), torch.Size([8, 768]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape, output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, train_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.train_df = train_df\n",
    "    self.test_df = test_df\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_token_len = max_token_len\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = ToxicCommentsDataset(\n",
    "      self.train_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "    self.test_dataset = ToxicCommentsDataset(\n",
    "      self.test_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=True\n",
    "    )\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size\n",
    "    )\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "data_module = ToxicCommentDataModule(\n",
    "  train_df,\n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentTagger(pl.LightningModule):\n",
    "  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    self.criterion = nn.BCELoss()\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "    output = self.classifier(output.pooler_output)\n",
    "    output = torch.sigmoid(output)\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels)\n",
    "    return loss, output\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    print(\"hello\")\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "  def training_epoch_end(self, outputs):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "      for out_labels in output[\"labels\"].detach().cpu():\n",
    "        labels.append(out_labels)\n",
    "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "        predictions.append(out_predictions)\n",
    "    labels = torch.stack(labels).int()\n",
    "    predictions = torch.stack(predictions)\n",
    "    for i, name in enumerate(types):\n",
    "      class_roc_auc = auroc(predictions[:, i], labels[:, i],len(types))\n",
    "      print(\"hello\")\n",
    "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=self.n_warmup_steps,\n",
    "      num_training_steps=self.n_training_steps\n",
    "    )\n",
    "    return dict(\n",
    "      optimizer=optimizer,\n",
    "      lr_scheduler=dict(\n",
    "        scheduler=scheduler,\n",
    "        interval='step'\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3a0lEQVR4nO3deVxUVf8H8M/sw74qiCKCmogriyLmVk+K2qLVo2iJWrlQT7m1WJplq2a7P3PNXNLcMq1sU8udRVHcd0VxARGQfRlm5vz+QKZIREaBy8x83q/XfQV3ztz7mRmSL+eee45MCCFARERERBZPLnUAIiIiIqoZLOyIiIiIrAQLOyIiIiIrwcKOiIiIyEqwsCMiIiKyEizsiIiIiKwECzsiIiIiK8HCjoiIiMhKKKUOYM2MRiOuXr0KJycnyGQyqeMQERGRBRJCIC8vDz4+PpDLq+6TY2FXi65evQpfX1+pYxAREZEVuHTpEpo0aVJlGxZ2tcjJyQlA2Qfh7OwscRoiIiKyRLm5ufD19TXVFVVhYVeLyi+/Ojs7s7AjIiKie1KdYV28eYKIiIjISrCwIyIiIrISLOyIiIiIrATH2BEREdUyo9EInU4ndQyqp1QqFRQKRY0ci4UdERFRLdLpdEhOTobRaJQ6CtVjrq6u8Pb2vud5b1nYERER1RIhBFJTU6FQKODr63vHyWXJ9gghUFhYiPT0dABAo0aN7ul4LOyIiIhqiV6vR2FhIXx8fGBvby91HKqn7OzsAADp6elo2LDhPV2W5Z8OREREtcRgMAAA1Gq1xEmovisv/EtLS+/pOCzsiIiIahnXC6c7qamfERZ2RERERFaChR0RERFV0KtXL0yYMEHqGACA6dOno2PHjlLHsBiSF3Zz586Fv78/tFotQkNDsWvXrirb79ixA6GhodBqtQgICMD8+fNvabN+/XoEBQVBo9EgKCgIGzZsqPD4zp078eijj8LHxwcymQwbN2685RhCCEyfPh0+Pj6ws7NDr169cOzYsXt6rURERGSeV155BX/++afUMW5r+/btkMlkyM7OljoKAIkLuzVr1mDChAmYOnUqkpKS0L17d/Tr1w8pKSmVtk9OTkb//v3RvXt3JCUlYcqUKRg3bhzWr19vahMXF4eoqChER0fj0KFDiI6OxuDBg5GQkGBqU1BQgA4dOmDOnDm3zTZr1ix89tlnmDNnDvbt2wdvb2/07t0beXl5NfcGEBER2ajqTtjs6OgIDw+PWk5zK4udUFpIqHPnziImJqbCvsDAQPH6669X2v61114TgYGBFfaNHTtWdOnSxfT94MGDRd++fSu0iYyMFEOGDKn0mADEhg0bKuwzGo3C29tbzJw507SvuLhYuLi4iPnz59/xdZXLyckRAEROTk61n0NERNajqKhIHD9+XBQVFUkdxSw9e/YU48ePN31fUlIiXn31VeHj4yPs7e1F586dxbZt20yPZ2RkiCFDhojGjRsLOzs70bZtW/Hdd9/dcsz//e9/YuLEicLDw0P06NFDbNu2TQAQW7duFaGhocLOzk5ERESIkydPmp739ttviw4dOpi+HzFihBgwYID4+OOPhbe3t3B3dxcvvPCC0Ol0pjZXr14V/fv3F1qtVjRr1kysXLlS+Pn5ic8///y2r7n8uB9++KFo1KiR8PPzE0II8e2334rQ0FDh6OgovLy8xNChQ8W1a9eEEEIkJycLABW2ESNGCCHKaomPPvpI+Pv7C61WK9q3by/WrVt32/NX9bNiTj0hWY+dTqfD/v370adPnwr7+/Tpg9jY2EqfExcXd0v7yMhIJCYmmm4Pvl2b2x2zMsnJyUhLS6twHI1Gg549e1Z5nJKSEuTm5lbYyLpsOX4NG5OuQAghdRQiskBCCBTq9JJs9/Lv1jPPPIM9e/Zg9erVOHz4MAYNGoS+ffvizJkzAIDi4mKEhoZi06ZNOHr0KMaMGYPo6OgKV8sAYNmyZVAqldizZw8WLFhg2j916lR8+umnSExMhFKpxLPPPltlnm3btuHcuXPYtm0bli1bhqVLl2Lp0qWmx4cPH46rV69i+/btWL9+PRYuXGiaALgqf/75J06cOIEtW7Zg06ZNAMrqlffeew+HDh3Cxo0bkZycjJEjRwIAfH19TVcNT506hdTUVHz55ZcAgDfffBNLlizBvHnzcOzYMUycOBHDhg3Djh077pjjXkg2QXFGRgYMBgO8vLwq7Pfy8kJaWlqlz0lLS6u0vV6vR0ZGBho1anTbNrc75u3OU/68fx/n4sWLt33ejBkz8M4771T7PGRZsgt1eH7FfuiNAseu5mBK/9acwoCIzFJUakDQW39Icu7j70bCXm3+r/1z585h1apVuHz5Mnx8fACUjXv7/fffsWTJEnz44Ydo3LgxXnnlFdNzXnrpJfz+++9Yt24dwsPDTftbtGiBWbNmmb4v/337wQcfoGfPngCA119/HQ8//DCKi4uh1WorzeTm5oY5c+ZAoVAgMDAQDz/8MP7880+MHj0aJ0+exNatW7Fv3z6EhYUBAL7++mu0bNnyjq/VwcEBX3/9dYV5B/9ZZAYEBGD27Nno3Lkz8vPz4ejoCHd3dwBAw4YN4erqCqBsyNdnn32Gv/76CxEREabn7t69GwsWLDC91tog+coT//7FKISo8pdlZe3/vd/cY9ZUtjfeeAOTJk0yfZ+bmwtfX1+zz0v1U9y5TOiNZT9vi3YlI79Ej/cHtoNCzuKOiKzXgQMHIITAfffdV2F/SUmJaeybwWDAzJkzsWbNGly5cgUlJSUoKSmBg4NDheeUF1r/1r59e9PX5Utqpaeno2nTppW2b9OmTYXVGRo1aoQjR44AKOs5UyqVCAkJMT3eokULuLm53fG1tmvX7pbJpJOSkjB9+nQcPHgQWVlZpjV/U1JSEBQUVOlxjh8/juLiYvTu3bvCfp1Oh+Dg4DvmuBeSFXaenp5QKBS39KSlp6ff0lNWztvbu9L2SqXS9MN1uza3O+btzgOU/SXxzzXb7nQcjUYDjUZT7fOQZdl9NgMA0LqRM06l5WLV3kvILzHgs8EdoFJIfoM5EVkAO5UCx9+NlOzcd8NoNEKhUGD//v23LHXl6OgIAPj000/x+eef44svvkC7du3g4OCACRMm3HIDwr8LvXIqlcr0dXkHSnkBdaf25c8pb3+7S87VuRT973wFBQXo06cP+vTpgxUrVqBBgwZISUlBZGRklTdXlGf55Zdf0Lhx4wqP1XadIFlhp1arERoaii1btuDxxx837d+yZQsGDBhQ6XMiIiLw888/V9i3efNmhIWFmT7kiIgIbNmyBRMnTqzQpmvXrtXO5u/vD29vb2zZssVUWet0OuzYsQMfffRRtY9D1iX2XCYAYFLv+1CiN2DC6oP47UAKuvy6CoM7+UL1fAzwr39siIj+SSaT3dXlUCkFBwfDYDAgPT0d3bt3r7TNrl27MGDAAAwbNgxAWWFz5swZtG7dui6jAgACAwOh1+uRlJSE0NBQAMDZs2fvajqSkydPIiMjAzNnzjRdgUtMTKzQpryHr3z5OACmKddSUlJq9bJrZST96Zo0aRKio6MRFhaGiIgILFy4ECkpKYiJiQFQdmnzypUrWL58OQAgJiYGc+bMwaRJkzB69GjExcVh8eLFWLVqlemY48ePR48ePfDRRx9hwIAB+PHHH7F161bs3r3b1CY/Px9nz541fZ+cnIyDBw/C3d0dTZs2hUwmw4QJE/Dhhx+iZcuWaNmyJT788EPY29vjqaeeqqN3h+qTyzcKkZxRAIVchvAAdzhrVXBQKzHxmz14esXHwAqgYNhwOLi7SB2ViKhG3XfffXj66acxfPhwfPrppwgODkZGRgb++usvtGvXDv3790eLFi2wfv16xMbGws3NDZ999hnS0tIkK+weeughjBkzBvPmzYNKpcLLL78MOzs7s4dlNW3aFGq1Gv/3f/+HmJgYHD16FO+9916FNn5+fpDJZNi0aRP69+8POzs7ODk54ZVXXsHEiRNhNBrRrVs35ObmIjY2Fo6OjhgxYkRNvuQKJL1+FBUVhS+++ALvvvsuOnbsiJ07d+LXX3+Fn58fACA1NbXCnHb+/v749ddfsX37dnTs2BHvvfceZs+ejSeffNLUpmvXrli9ejWWLFmC9u3bY+nSpVizZk2FwZuJiYkIDg429cZNmjQJwcHBeOutt0xtXnvtNUyYMAEvvPACwsLCcOXKFWzevBlOTk61/bZQPRR7tqy3rkMTFzhry3rlHghsiAXRoaY2zy3bh5zCe1u8mYioPlqyZAmGDx+Ol19+Ga1atcJjjz2GhIQEUy/WtGnTEBISgsjISPTq1Qve3t4YOHCgZHmXL18OLy8v9OjRA48//jhGjx4NJyen296McTsNGjTA0qVLsW7dOgQFBWHmzJn45JNPKrRp3Lgx3nnnHbz++uvw8vLCiy++CAB477338NZbb2HGjBlo3bo1IiMj8fPPP8Pf37/GXmdlZILzNtSa3NxcuLi4ICcnB87OzlLHoXswblUSfjp0FS892AIv92n19wMFBcDNMSatJ36PZn4N8e1zneHpyLGWRFQ2DUhycrJphSWSxuXLl+Hr64utW7fiP//5j9RxKlXVz4o59QRHfBPdgRACsefKbpy4v4Xnbdt5OKpxIjUXgxfEITWnqK7iERHRv/z111/46aefkJycjNjYWAwZMgTNmjVDjx49pI5W61jYEd3BqWt5yMjXwU6lQHBT19u2+/bZzvBx0eL89QL8d14cLmYW1F1IIiIyKS0txZQpU9CmTRs8/vjjaNCgAbZv337L3bTWiIUd0R3sPlPWW9fJ3x0a5e2nC/Bv4Ih1z3dFMw97XMkuwqD5cTh9jWsLExHVtcjISBw9ehSFhYW4du0aNmzYYBq/b+1Y2BHdQfk0J91a3HkR6saudlgbE4FAbyek55UgakEcjlzOqe2IREREAFjYEVWp1GBE/Pmywq6q8XX/1NBJi9VjuqCDrytuFJZi6KJ47E3Oqs2YREREAFjYEVXp4KVsFOoMcHdQo7V39e9sdrVXY+WocIT7uyO/RI/h3yRgx+nrtZiUiIiIhR1RlfbcXEYsorkH5GauCeuoUWLZs53Rq1UDFJcaMWrZPvx+NLU2YhIREQFgYUdUpfLCrtvtLsM6OABClG2VrIGoVSmwMDoMD7drhFKDwP++S8IPBy7XZmQiIrJhLOyIbqOgRI+klGwAwP3Nqze+rjJqpRyzhwZjUGgTGIwCk9YewrdxF2omJBER1WvTp09Hx44d6+x8LOyIbmNvchb0RgFfdzs09bC/p2Mp5DJ89GR7jOzaDAAw7cdjmLf9XA2kJCIi+hsLO6Lb2H3zMuy99Nb9k1wuw9uPBuGlB1sAAD76/SQ+/uMkuKofEdkanU4ndQSrxcKO6DbKx9dVd5qT6pDJZHi5Tyu83i8QAPDVtnN45+fjMBpZ3BFR/fDzzz/D1dUVRqMRAHDw4EHIZDK8+uqrpjZjx47F0KFDAQCZmZkYOnQomjRpAnt7e7Rr1w6rVq2qcMxevXrhxRdfxKRJk+Dp6YnevXtj+/btkMlk+OOPPxAcHAw7Ozs8+OCDSE9Px2+//YbWrVvD2dkZQ4cORWFhoelYzZo1wxdffFHh+B07dsT06dNN38tkMsybNw/9+vWDnZ0d/P39sW7duipftxACs2bNQkBAAOzs7NChQwd8//33psfL8/75558ICwuDvb09unbtilOnTlU4zsyZM+Hl5QUnJyc899xzKC4uvvObXoNY2BFV4npeCU6mla0a0bX5nScmNldMz+Z4f2BbyGTA0tgLeG39YegNxho/DxGRuXr06IG8vDwkJSUBAHbs2AFPT0/s2LHD1Gb79u3o2bMngLLF60NDQ7Fp0yYcPXoUY8aMQXR0NBISEiocd9myZVAqldizZw8WLFhg2j99+nTMmTMHsbGxuHTpEgYPHowvvvgC3333HX755Rds2bIF//d//2f265g2bRqefPJJHDp0CMOGDcPQoUNx4sSJ27Z/8803sWTJEsybNw/Hjh3DxIkTMWzYsAqvGwCmTp2KTz/9FImJiVAqlXj22WdNj61duxZvv/02PvjgAyQmJqJRo0aYO3eu2dnviaBak5OTIwCInJwcqaOQmTYmXRZ+kzeJvl/srNXz/HDgkgh44xfhN3mTeH5FoigpNdTq+YiobhUVFYnjx4+LoqKiig/k51dv0+kkyR0SEiI++eQTIYQQAwcOFB988IFQq9UiNzdXpKamCgDixIkTt31+//79xcsvv2z6vmfPnqJjx44V2mzbtk0AEFu3bjXtmzFjhgAgzp07Z9o3duxYERkZafrez89PfP755xWO1aFDB/H222+bvgcgYmJiKrQJDw8Xzz//fKV58/PzhVarFbGxsRX2P/fcc2Lo0KG3zfvLL78IAKbPNyIiotLzdujQodLz/tNtf1aEefUEe+yIKvH3NCc131v3T48HN8FXT4VArZDj1yNpGL08EUU6Q62ek4jqAUfH6m0LF0oSr1evXti+fTuEENi1axcGDBiAtm3bYvfu3di2bRu8vLwQGFg2pMRgMOCDDz5A+/bt4eHhAUdHR2zevBkpKSkVjhkWFlbpudq3b2/62svLC/b29ggICKiwLz093ezXEBERccv3t+uxO378OIqLi9G7d284OjqatuXLl+PcuYo3uv0zb6NGjQDAlO/EiROVnrcuKev0bEQWQAiBPWfNW0bsXvRt642vR4RhzLeJ2HH6OkYs2YvFI8LgpFXV+rmJiCrTq1cvLF68GIcOHYJcLkdQUBB69uyJHTt24MaNG6bLsADw6aef4vPPP8cXX3yBdu3awcHBARMmTLjlBgmHSub6BACV6u9/62QyWYXvy/eVj/cDALlcfstNZ6WlpdV6XTJZ5RPNlx//l19+QePGjSs8ptFoqsz7z+fXB+yxI/qXi5mFuJJdBJVChs7+7nVyzh73NcC3z4XDSaPE3uQsPP11Am4U8K4xIquVn1+9bcwYSeKVj7P74osv0LNnT8hkMvTs2RPbt2+vML4OgKlHb9iwYejQoQMCAgJw5syZWsvWoEEDpKb+vYpPbm4ukpOTb2kXHx9/y/flvYz/FhQUBI1Gg5SUFLRo0aLC5uvrW+1srVu3rvS8dYk9dkT/sudc2WXY4KZusFfX3f8inZq5Y9WYLohenIDDl3MQtTAOK54LR0NnbZ1lIKI6cpveq/rCxcUFHTt2xIoVK/Dll18CKCv2Bg0ahNLSUvTq1cvUtkWLFli/fj1iY2Ph5uaGzz77DGlpaWjdunWtZHvwwQexdOlSPProo3Bzc8O0adOgUChuabdu3TqEhYWhW7duWLlyJfbu3YvFixdXekwnJye88sormDhxIoxGI7p164bc3FzExsbC0dERI0aMqFa28ePHY8SIERXOe+zYsQqXlmsbe+yI/mVPDc9fZ462jV2wdmwEGjppcPpaPgYviMPlG4V3fiIRUQ174IEHYDAYTEWcm5sbgoKC0KBBgwpF27Rp0xASEoLIyEj06tUL3t7eGDhwYK3leuONN9CjRw888sgj6N+/PwYOHIjmzZvf0u6dd97B6tWr0b59eyxbtgwrV65EUFDQbY/73nvv4a233sKMGTPQunVrREZG4ueff4a/v3+1s0VFReGtt97C5MmTERoaiosXL+L555+/q9d5t2Ti3xeqqcbk5ubCxcUFOTk5cHZ2ljoOVYPRKBDy/hZkF5Zi/fMRCPWrm0ux/5aSWYinvo7H5RtFaOSixcpR4Qho4ChJFiK6e8XFxUhOToa/vz+0Wva+1xWZTIYNGzbUaoFZ06r6WTGnnmCPHdE/HE/NRXZhKRw1SrRv4ipZjqYe9vg+piuaN3BAak4xBi+Iw/GruZLlISIiy8DCjugfypcRC/d3h0oh7f8e3i5arB0bgTY+zsjI12HIwjgcSLkhaSYiIqrfWNgR/UNtLCN2LzwcNfhudBeE+rkht1iPYV8nIPbmzR1ERFQ5IYRFXYatSSzsiG4qLjVg34UsAEC3lvWjsAMAFzsVvn2uM+5v4YFCnQEjl+zDnyeuSR2LiIjqIRZ2RDcdSLmB4lIjGjhp0LJh/bpRwV6txOIRndA7yAs6vRFjv92Pnw9dlToWERHVMyzsiG6KLV9tornHbWcnl5JWpcDcp0MwoKMP9EaBcauTsGZfyp2fSESS4wQUdCc19TPCwo7opvIbJ7rWk/F1lVEp5PhscEcM7dwUQgCT1x/B4t23zrhORPVD+cS5/15ei+jfCgvL5iz995Jq5uLKE0QAcotLcfhyNgAzb5wwGoHyRaVbtwbktf+3kkIuw4ePt4WjRoFFu5Lx3qbjKCjR46UHW9TLnkYiW6ZUKmFvb4/r169DpVJBXgf/RpBlEUKgsLAQ6enpcHV1rXQVDXOwsCMCEH8uE0YBBHg6oLGrXfWfWFQEtG1b9nV+fp0tEySTyTClf2s4aVX4bMtpfLblNApK9Hi9XyCLO6J6RCaToVGjRkhOTsbFixeljkP1mKurK7y9ve/5OCzsiPD3NCddW3hInKT6ZDIZxv2nJRw0Sry36TgW7DyP/BI93hvQFnI5izui+kKtVqNly5a8HEu3pVKp7rmnrhwLOyIAe86V3zhRf8fX3c5z3fzhqFHg9R+OYGVCCgpK9PhkUAcoJZ5gmYj+JpfLuaQY1Qn+y082Ly2nGGfT8yGTAV0tsLADgKhOTTF7SDCUchk2HryKF1YeQIneIHUsIiKqYyzsyOaVX4Zt19gFLvb3djeSlB7t4IOFw0OhVsqx+fg1jFqWiEKdXupYRERUh1jYkc3bc65+LSN2Lx4M9MLSZzrBXq3ArjMZiF68FzlFpVLHIiKiOsLCjmyaEMLUY9fNCgo7oOxy8opR4XDWKrH/4g08tSgemfklUsciIqI6wMKObNq56/m4llsCtVKOUD83qePUmJCmblgzNgKejmocu5qLwQvikJZTLHUsIiKqZSzsyKbtubmMWKdmbtCqauZW8/qidSNnrB0bAR8XLc5dL8CgBbFIySyUOhYREdUiFnZk08qXEbOG8XWVCWjgiLUxEWjmYY9LWUX47/xYnLmWJ3UsIiKqJSzsyGbpDUbE3+v8dVotsG1b2VZP56hq4maPtWMj0MrLCel5JRi8IA5HLudIHYuIiGoBCzuyWUeu5CCvRA9nrRJtG7vc3UEUCqBXr7KthmYNrw0NnbVYPaYLOjRxwY3CUjy1KB77LmRJHYuIiGoYCzuyWaZlxJp7QmEDS3C5OaixYlQ4Ovu7I69Ej+jFCdh15rrUsYiIqAaxsCOb9ff4OstZH/ZeOWlVWPZMZ/Rq1QDFpUY8tzQRvx9NkzoWERHVEBZ2ZJOKdAYcuJgNwHpvnLgdO7UCC6PD0K+tN3QGI/733QFsSLosdSwiIqoBLOzIJu27kAWdwQgfFy38PR2kjlPn1Eo5/m9oMP4b2gQGo8CktYewIv6i1LGIiOgesbAjm2QaX9fCEzKZ9Y+vq4xSIcesJ9tjRIQfhADe3HgUC3ackzoWERHdAxZ2ZJPK14e1lmXE7pZcLsP0x9rgfw80BwDM+O0kPt18CkIIiZMREdHdYGFHNierQIdjV3MBAF1t6MaJ25HJZHg1MhCv9W0FAPi/v87inZ+Pw2hkcUdEZGlY2JHNiTuXCSGA+7wc0dCpfk4qLIUXerXAewPaAACWxl7A6z8choHFHRGRRWFhRzan/DKsrd0NWx3REc3w6aAOkMuAtYmXMW5VEnR6o9SxiIiomljYkc0pv3HirpcRs3JPhjbBV0+FQKWQ4ZcjqRj7bSKKSw1SxyIiompgYUc25VJWIS5mFkIhlyE8wF3qOPVWv3aN8PWITtCq5Nh26jpGLtmL/BK91LGIiOgOWNiRTYm9eRm2o68rnLQqidPUbz3va4Dlz4bDUaNE/PksPP11ArILdVLHIiKiKrCwI5uy+2wmAI6vq67O/u74bnQ43OxVOHQpG0MWxuN6XonUsYiI6DZY2JHNMBoFYk3j6zjNSXW1b+KKNWMj0MBJg5NpeRi8IA5XsoukjkVERJVgYUc249S1PGQW6GCnUiC4qZvUcSzKfV5OWDc2Ao1d7ZCcUYBB82KRnFEgdSwiIvoXFnZkM8rvhg0PcIdayR99czXzdMD3z0cgoIEDruYUY9D8OJxIzZU6FhER/QN/u5HN4DQn966Rix3Wjo1A60bOyMgvwZCF8Th4KVvqWEREdBMLO7IJOr0RCclZAHjjxL3ydNRg9eguCGnqipyiUjy9KB5x5zKljkVERGBhRzbi0OVsFOoM8HBQI9DbSeo4Fs/FXoVvnwtH1+YeKNAZMHLJXmw7mS51LCIim8fCjmzC7jNll2EjmntALpfV3IELCoAGDcq2Atu6mcBBo8Q3IzvhodYNUaI3YvTyRPxyOFXqWERENo2FHdmE8vF13WrjMmxGRtlmg7QqBeYNC8WjHXygNwq8tOoA1iZekjoWEZHNYmFHVi+/RG8a4M/xdTVPpZDji6iOGNLJF0YBvPb9YSzZkyx1LCIim8TCjqze3uRM6I0CTd3t4etuL3Ucq6SQyzDjiXYY1c0fAPDOz8cx568zEEJInIyIyLZIXtjNnTsX/v7+0Gq1CA0Nxa5du6psv2PHDoSGhkKr1SIgIADz58+/pc369esRFBQEjUaDoKAgbNiwwezz5ufn48UXX0STJk1gZ2eH1q1bY968eff2YkkSe7iMWJ2QyWSY+nBrTHzoPgDAJ5tPY+bvJ1ncERHVIUkLuzVr1mDChAmYOnUqkpKS0L17d/Tr1w8pKSmVtk9OTkb//v3RvXt3JCUlYcqUKRg3bhzWr19vahMXF4eoqChER0fj0KFDiI6OxuDBg5GQkGDWeSdOnIjff/8dK1aswIkTJzBx4kS89NJL+PHHH2vvDaFaUavj66gCmUyG8Q+1xJsPtwYALNhxHm9uPAqjkcUdEVFdkAkJ/5wODw9HSEhIhZ6w1q1bY+DAgZgxY8Yt7SdPnoyffvoJJ06cMO2LiYnBoUOHEBcXBwCIiopCbm4ufvvtN1Obvn37ws3NDatWrar2edu2bYuoqChMmzbN1CY0NBT9+/fHe++9V63Xl5ubCxcXF+Tk5MDZ2blaz6GadT2vBJ0+2AoAODCtN9wd1DV7goICwNGx7Ov8fMDBoWaPb8FW7U3BlA1HIATweHBjfPzf9lAqJL9IQERkccypJyT7V1an02H//v3o06dPhf19+vRBbGxspc+Ji4u7pX1kZCQSExNRWlpaZZvyY1b3vN26dcNPP/2EK1euQAiBbdu24fTp04iMjLztayopKUFubm6FjaQVe66st66Nj3PNF3VUpaGdm+KLqI5QymXYkHQFL6w8gBK9QepYRERWTbLCLiMjAwaDAV5eXhX2e3l5IS0trdLnpKWlVdper9cj4+Z0E7drU37M6p539uzZCAoKQpMmTaBWq9G3b1/MnTsX3bp1u+1rmjFjBlxcXEybr6/vHd4Fqm2mZcR4GVYSAzo2xvxhoVAr5dh8/BpGLUtEoU4vdSwiIqsl+XURmaziZLFCiFv23an9v/dX55h3ajN79mzEx8fjp59+wv79+/Hpp5/ihRdewNatW2+b7Y033kBOTo5pu3SJ83lJSQjBGyfqgYeCvLBkZCfYqxXYdSYDwxfvRW5xqdSxiIisklKqE3t6ekKhUNzSO5eenn5Lb1o5b2/vStsrlUp4eHhU2ab8mNU5b1FREaZMmYINGzbg4YcfBgC0b98eBw8exCeffIKHHnqo0nwajQYajaY6L5/qwMXMQlzJLoJaIUenZm61cxKVCnj77b+/pkrd38IT3z4XjmeW7EXixRt4alE8lj8bzsvjREQ1TLIeO7VajdDQUGzZsqXC/i1btqBr166VPiciIuKW9ps3b0ZYWBhUN3+p3q5N+TGrc97S0lKUlpZCLq/49igUChiNRjNfKUll983LsMFNXWGvrqW/YdRqYPr0sk3NIqUqoX5uWDWmCzwc1Dh6JRdRC+JwLbdY6lhERFZF0kuxkyZNwtdff41vvvnGNKVISkoKYmJiAJRd2hw+fLipfUxMDC5evIhJkybhxIkT+Oabb7B48WK88sorpjbjx4/H5s2b8dFHH+HkyZP46KOPsHXrVkyYMKHa53V2dkbPnj3x6quvYvv27UhOTsbSpUuxfPlyPP7443Xz5tA94zQn9U8bHxesGRuBRi5anEnPx6D5cbiUVSh1LCIi6yEk9tVXXwk/Pz+hVqtFSEiI2LFjh+mxESNGiJ49e1Zov337dhEcHCzUarVo1qyZmDdv3i3HXLdunWjVqpVQqVQiMDBQrF+/3qzzCiFEamqqGDlypPDx8RFarVa0atVKfPrpp8JoNFb7teXk5AgAIicnp9rPoZqhNxhFh3f+EH6TN4n9F7OkjkP/kpJZIHrM+kv4Td4kwj/YKs5cy5M6EhFRvWVOPSHpPHbWjvPYSefI5Rw8Omc3nDRKJL3Vm/On1UPpucUYtjgBp6/lw91BjeXPdkbbxi5SxyIiqncsYh47otpUPr4uPMCDRV091dBZizVjItC+iQuyCnQYuige+y9mSR2LiMii8TceWaXyiYnvb+EhcRKqipuDGitHhaNzM3fkFesx7Ou92H0mQ+pYREQWi4UdWZ3iUgP2Jpf1/PDGifrPSavCsmc7o8d9DVBUasCzS/dh87HKJyknIqKqsbAjq3Pg4g2U6I1o6KRBi4aOUseharBTK7BoeCj6tfWGzmDE8ysP4MeDV6SORURkcVjYkdXZc+7vZcSqWsWE6heNUoH/GxqMJ0Iaw2AUmLDmIL5LSJE6FhGRRWFhR1ZnN5cRs1hKhRyf/LcDhkf4QQhgyoYjWLjznNSxiIgsBgs7sio5RaU4cjkbAG+csFRyuQzvPNYGz/dqDgD48NeT+GzzKXBmJiKiO2NhR1Yl/nwmjAIIaOCARi52UsehuySTyTC5byBejWwFAJj911m8t+kEizsiojtgYUdWhcuIWZf/PdAC7zzWBgDwzZ5kvPHDERiMLO6IiG6HhR1ZlfKJibs2Z2FnLUZ0bYZPBnWAXAas3ncJ41cnQac3Sh2LiKheYmFHViM1pwjnrxdALgMiAji+zpr8N7QJvnoqBCqFDJsOpyJmxX4UlxqkjkVEVO+wsCOrsefm3bDtmrjCxV4lcRqqaf3aNcKi4WHQKOX462Q6nlmyD/kleqljERHVKyzsyGqUj6+7vzl766xVr1YNsfzZznDUKBF3PhPDvk5AdqFO6lhERPUGCzuyCkII3jhhI8IDPPDd6HC42qtw8FI2hiyMx/W8EqljERHVCyzsyCqcTc9Hel4JNEo5QvzcpI5Dtax9E1esGROBBk4anEzLQ9SCOFzJLpI6FhGR5FjYkVUovxu2UzN3aFUKidNQXWjl7YR1YyPQ2NUO5zMKMHh+HJIzCqSORUQkKRZ2ZBX2SLWMWHExMGhQ2VZcXLfnJjTzdMC6mAgEeDrgSnYRBs2Pw8m0XKljERFJhoUdWTy9wYiE82WFXZ2PrzMYgO+/L9sMnH5DCj6udlgzNgKB3k7IyC/BkIXxOHQpW+pYRESSYGFHFu/wlRzklejhYqdCkI+z1HFIAg2cNFg9pgs6+roiu7AUTy2KR/zNYp+IyJawsCOLt+dM+WoTHlDIZRKnIam42quxYlQ4IgI8UKAzYMQ3e7HtVLrUsYiI6hQLO7J45TdO1Pn4Oqp3HDVKLHmmEx4MbIgSvRFjlifi1yOpUsciIqozLOzIohXq9EhKyQbAwo7KaFUKLIgOxSPtG6HUIPDidwewLvGS1LGIiOoECzuyaPsu3IDOYERjVzs087CXOg7VEyqFHF8OCUZUmC+MAnj1+8NYuidZ6lhERLWOhR1ZtFjTZVgPyGQcX0d/U8hlmPlkOzx7vz8AYPrPx/HVtrMSpyIiql0s7MiicXwdVUUmk2HaI60x7j8tAQAf/3EKM387CSGExMmIiGoHCzuyWFkFOhy7WjYZbdfmLOyocjKZDJN634cp/QMBAPN3nMNbPx6D0cjijoisj1LqAER3K+5c2Txlgd5OaOCkkSaEXA707Pn311RvjenRHI4aFaZuPIJv4y+ioESPWf9tD6WCnxsRWQ8WdmSxyi/DStpbZ2cHbN8u3fnJLE+FN4WDRoFJaw/hh6QrKNQZ8OXQjtAoub4wEVkH/qlKFmvPzcKuW0sPiZOQJRnQsTHmPR0CtUKO34+lYfTy/SjScTk4IrIOLOzIIl3KKkRKViGUchk6+7OwI/P0aeONb0Z2gp1KgZ2nr2PEN3uRW1wqdSwionvGwo4sUnlvXUdfVzhqOKKAzNetpSdWjOoMJ60Sey9k4elFCbhRoJM6FhHRPWFhRxZpz80bJzjNCd2LUD93rBrdBR4Oahy5koOohXFIzy2WOhYR0V1jYUcWx2gUpomJu7VkYUf3pm1jF6wZGwFvZy1OX8vHoAVxuJRVKHUsIqK7wsKOLM7JtDxkFuhgr1agQxNXqeOQFWjR0BHrYiLQ1N0eFzMLMWh+HM6m50sdi4jIbCzsyOLEnivrrQv3d4dayR9hqhm+7vZYFxOBlg0dkZZbjKgFcTh2NUfqWEREZuFvRbI4XEaMaouXsxZrxkagbWNnZBboMHRhPPZfvCF1LCKiamNhRxZFpzci4XwWABZ2VDvcHdT4bnQXhPm5IbdYj+jFCaa7sImI6jsWdmRRDl7KRlGpAZ6OarTycpI6DlkpZ60Ky5/rjO4tPVGoM+CZpfuw9fg1qWMREd0RCzuyKOWXYSOae0Iul0mchqyZvVqJr0eEIbKNF3R6I2JW7MePB69IHYuIqEos7MiimJYRa8HVJqj2aZQKfPVUCJ4Ibgy9UWDCmoNYtTdF6lhERLfFwo4sRl5xKQ5eygbA8XVUd5QKOT4Z1AHDujSFEMAbPxzB17vOSx2LiKhSLOzIYuxNzoLBKODnYY8mbvZSxyEbIpfL8N6AthjbMwAA8P4vJ/DF1tMQQkicjIioIhZ2ZDE4zQlJSSaT4fW+gXilz30AgC+2nsEHv5xgcUdE9QoLO7IYsWdvrg/bnIUdSUMmk+HFB1vi7UeDAABf707GGz8cgcHI4o6I6gcWdmQR0vOKcepaHmQyIKI5b5wgaT1zvz9mPdkechmwet8lTFhzEKUGo9SxiIhY2JFlKO+ta+PjDHcHtcRpiIDBnXwxe2gwlHIZfj50Fc+v2I/iUoPUsYjIxrGwI4tQPs0JL8NSffJIex8sGh4GjVKOrSfS8ezSfSgo0Usdi4hsGAs7qveEEH8XdvXtxonSUuCrr8q20lKp05AEHghsiKXPdIaDWoHYc5kYtjgBOYX8WSAiabCwo3ovOaMAV3OKoVbI0amZu9RxKtLpgBdfLNt0OqnTkEQimntg5egucLFTISklG0MWxSMjv0TqWERkg1jYUb2351zZ+Lrgpq6wUyskTkNUuY6+rlgztgs8HTU4kZqLwQvikJpTJHUsIrIxLOyo3ttzpuwybPeW9ewyLNG/BHo7Y+3YLvBx0eL89QL8d14cLmYWSB2LiGwICzuq1wxGgdhzZYVd1/o2vo6oEgENHLHu+a5o5mGPK9lFGDQ/Dqev5Ukdi4hsBAs7qteOXc1BbrEeThol2jd2kToOUbU0drXD2pgIBHo7IT2vBFEL4nD4crbUsYjIBrCwo3qtfBmxLs09oFTwx5UsR0MnLVaP6YIOvq64UViKpxYlYG9yltSxiMjK8Tcl1Wt/LyPG1SbI8rjaq7FyVDi6BLgjv0SP4d8kYMfp61LHIiIrxsKO6q3iUgP2Xijr4ejGGyfIQjlqlFj6TGc80KoBikuNGLVsH34/mip1LCKyUizsqN7af/EGdHojvJw1aN7AUeo4RHdNq1JgQXQYHm7XCKUGgRdWHsD6/ZeljkVEVoiFHdVb/1xGTCaTSZyG6N6olXLMHhqMwWFNYBTAy+sOYXncBaljEZGVYWFH9Va9XUbsnxwcACHKNgcHqdNQPaeQyzDzifZ45v5mAIC3fjyGudvPShuKiKzKXRV2er0eW7duxYIFC5CXVzY/09WrV5Gfn1+j4ch25RSW4siVHAD1vLAjMpNcLsNbjwRh3IMtAACzfj+FWb+fhBBC4mREZA2U5j7h4sWL6Nu3L1JSUlBSUoLevXvDyckJs2bNQnFxMebPn18bOcnGxJ3PhFEAzRs4wNtFK3Ucoholk8kwqU8rOGiUmPHbSczdfg4FJXq8/WgbyOUcdkBEd8/sHrvx48cjLCwMN27cgJ2dnWn/448/jj///LNGw5HtKr8M2429dWTFxvZsjvcHtoVMBiyLu4jX1h+G3mCUOhYRWTCze+x2796NPXv2QK1WV9jv5+eHK1eu1Fgwsm17zlnA+DqiGjCsix8cNUq8vO4Qvt9/GQUlenw5JBhqJYdAE5H5zP6Xw2g0wmAw3LL/8uXLcHJyMjvA3Llz4e/vD61Wi9DQUOzatavK9jt27EBoaCi0Wi0CAgIqvfS7fv16BAUFQaPRICgoCBs2bLir8544cQKPPfYYXFxc4OTkhC5duiAlJcXs10jmSc0pwvnrBZDLgPAATkxM1m9gcGPMezoEaoUcvx1Nw+jliSjS3frvLBHRnZhd2PXu3RtffPGF6XuZTIb8/Hy8/fbb6N+/v1nHWrNmDSZMmICpU6ciKSkJ3bt3R79+/W5bPCUnJ6N///7o3r07kpKSMGXKFIwbNw7r1683tYmLi0NUVBSio6Nx6NAhREdHY/DgwUhISDDrvOfOnUO3bt0QGBiI7du349ChQ5g2bRq0Wo73qm17bq420b6JK1zsVBKnIaobfdp4Y/HIMNipFNhx+jpGfLMXecWlUsciIgsjE2beinX16lU88MADUCgUOHPmDMLCwnDmzBl4enpi586daNiwYbWPFR4ejpCQEMybN8+0r3Xr1hg4cCBmzJhxS/vJkyfjp59+wokTJ0z7YmJicOjQIcTFxQEAoqKikJubi99++83Upm/fvnBzc8OqVauqfd4hQ4ZApVLh22+/rfbr+bfc3Fy4uLggJycHzs7Od30cWzNxzUFsSLqCFx9ogVciW0kdh6hOJV7IwjNL9iGvRI/2TVyw7JnOcHNQ3/mJRGS1zKknzO6x8/HxwcGDB/Hqq69i7NixCA4OxsyZM5GUlGRWUafT6bB//3706dOnwv4+ffogNja20ufExcXd0j4yMhKJiYkoLS2tsk35MatzXqPRiF9++QX33XcfIiMj0bBhQ4SHh2Pjxo1VvqaSkhLk5uZW2Mg8QgjsvnnjRNcWvAxLtiesmTtWjekCN3sVDl/OQdTCOKTnFksdi4gshNmF3c6dO6FSqfDMM89gzpw5mDt3LkaNGgWVSoWdO3dW+zgZGRkwGAzw8vKqsN/LywtpaWmVPictLa3S9nq9HhkZGVW2KT9mdc6bnp6O/Px8zJw5E3379sXmzZvx+OOP44knnsCOHTtu+5pmzJgBFxcX0+br61uNd4L+6Wx6Pq7nlUCjlCOkqZvUcYgk0baxC9aOjUBDJw1OX8vHoAVxuHyjUOpYRGQBzC7sHnjgAWRlZd2yPycnBw888IDZAf69VJQQosrloypr/+/91TlmVW2MxrLpBgYMGICJEyeiY8eOeP311/HII49UOU/fG2+8gZycHNN26dKl27alypX31nX2d4dWpZA4DZF0Wno54fuYrmjiZoeLmYUYND8O565zEngiqprZhd3tCq/MzEw4mLGkkqenJxQKxS29c+np6bf0ppXz9vautL1SqYSHh0eVbcqPWZ3zenp6QqlUIigoqEKb1q1bV3lXrEajgbOzc4WNzGMRy4gR1ZGmHvb4PqYrmjdwQGpOMaIWxOH4VQ7xIKLbq3Zh98QTT+CJJ56ATCbDyJEjTd8/8cQTGDBgACIjI9G1a9dqn1itViM0NBRbtmypsH/Lli23PU5ERMQt7Tdv3oywsDCoVKoq25QfszrnVavV6NSpE06dOlWhzenTp+Hn51ft10jm0RuMiD9f1hvMiYmJyni7aLF2bATa+DgjI1+HIQvjcCDlhtSxiKieqvYExS4uLgDKeuycnJwqrDqhVqvRpUsXjB492qyTT5o0CdHR0QgLC0NERAQWLlyIlJQUxMTEACi7tHnlyhUsX74cQNkdsHPmzMGkSZMwevRoxMXFYfHixaa7XYGylTF69OiBjz76CAMGDMCPP/6IrVu3Yvfu3dU+LwC8+uqriIqKQo8ePfDAAw/g999/x88//4zt27eb9Rqp+g5dzkF+iR6u9ioENWJvJ1E5D0cNvhvdBc8u3Yf9F29g2NcJ+Hp4GLryDyAi+jdhpunTp4v8/Hxzn3ZbX331lfDz8xNqtVqEhISIHTt2mB4bMWKE6NmzZ4X227dvF8HBwUKtVotmzZqJefPm3XLMdevWiVatWgmVSiUCAwPF+vXrzTpvucWLF4sWLVoIrVYrOnToIDZu3GjWa8vJyREARE5OjlnPs1Vfbj0t/CZvEs+vSJQ6ClG9VFBSKp5eFC/8Jm8SLaf+KrYeT5M6EhHVAXPqCbPnsaPq4zx25olaEIeE5Cx88HhbPB3OS95ElSkuNeClVUnYcvwalHIZPo/qiEc7+Egdi4hqkTn1hNlrxQLA999/j7Vr1yIlJQU6na7CYwcOHLibQ5KNK9TpTeOG7m/Oy0tEt6NVKTD36RC8su4Qfjx4FeNWJ6FQp0dUp6ZSRyOiesDsu2Jnz56NZ555Bg0bNkRSUhI6d+4MDw8PnD9/Hv369auNjGQD9iZnodQg0NjVDn4e9lLHIarXVAo5Ph/cEU+FN4UQwOT1R7B4d7LUsYioHjC7sJs7dy4WLlyIOXPmQK1W47XXXsOWLVswbtw45OTk1EZGsgGx58rWh72/hUeV8xgSURm5XIYPBrbFmB4BAID3Nh3H7D/PgKNriGyb2YVdSkqKaVoQOzs75OXlAQCio6Mr3J1KZI7dZzh/HZG5ZDIZ3ugXiEm97wMAfLblNGb8dpLFHZENM7uw8/b2RmZmWe+Kn58f4uPjAQDJycn8x4TuSmZ+CY6nlk262tXSxtcZjcCxY2XbzRVLiOqSTCbDuP+0xLRHyiZUX7jzPKZuPAqDkf8eE9kiswu7Bx98ED///DMA4LnnnsPEiRPRu3dvREVF4fHHH6/xgGT94s6X/aEQ6O2EBk4aidOYqagIaNu2bCsqkjoN2bDnuvnjoyfbQSYDvktIwaS1B1Fq4B8bRLbG7LtiFy5caFpLNSYmBu7u7ti9ezceffTRChP8ElUXlxEjqhlRnZrCXq3ExDUH8ePBqyjUGfB/Q4O57jKRDTGrx06v1+O9995Damqqad/gwYMxe/ZsjBs3Dmq1usYDkvXbfbOw4zJiRPfu0Q4+WDg8FGqlHFuOX8OoZYko1OmljkVEdcSswk6pVOLjjz+GwWCorTxkY1IyC3EpqwhKuQyd/d2ljkNkFR4M9MKyZzrDQa3A7rMZiF68FzlFpVLHIqI6YPYYu4ceeojrpVKN2XOurLcuuKkrHDR3NV82EVUiorkHVowKh7NWif0Xb2Downhk5pdIHYuIapnZv0n79euHN954A0ePHkVoaCgcHBwqPP7YY4/VWDiyfuWXYS3ublgiCxDc1A1rxkYgenECjqfmYvCCOKwYFY5GLnZSRyOiWmL2WrFy+e07+WQyGS/T/gPXiq2a0SgQ9sFWZBXosC4mAp2aWeCl2IICwNGx7Ov8fOBff+gQ1Qfnr+dj2NcJuJpTjCZudlg5Khx+HvxZJbIU5tQTZl+KNRqNt91Y1JE5TqTlIqtAB3u1Ah2auEodh8hqBTRwxNqYCDTzsMflG0UYND8OZ67lSR2LiGqB2YUdUU0pn+Yk3N8daiV/FIlqUxM3e6wdG4FWXk5IzyvB4AVxOHqFy0ASWRv+NiXJ7Dlbvj4sx9cR1YWGzlqsHtMFHZq44EZhKYYujMe+C1lSxyKiGsTCjiRRojdgb3LZL5RuLS24sNNqgW3byjatVuo0RHfk5qDGilHh6OzvjrwSPaIXJ2Dn6etSxyKiGsLCjiSRlJKNolIDPB3VaOXlJHWcu6dQAL16lW0Kzu5PlsFJq8KyZzqj530NUFxqxKhlifj9aJrUsYioBrCwI0nE/mOaE5lMJnEaIttjp1Zg0fAw9G/nDZ3BiP99dwAbki5LHYuI7pHZ89jl5uZWul8mk0Gj0XBZMaoWLiNGJD21Uo7ZQ4Jhrz6C7/dfxsQ1h5BfYkB0Fz+poxHRXTK7sHN1da2yh6VJkyYYOXIk3n777SrnvCPblVdcikOXy+7G69rCQ+I0RLZNqZBj1pPt4aBWYFncRUzbeBQFJXrE9GwudTQiugtmF3ZLly7F1KlTMXLkSHTu3BlCCOzbtw/Lli3Dm2++ievXr+OTTz6BRqPBlClTaiMzWbiE81kwGAWaedijiZu91HGIbJ5cLsP0x9rAUavEV9vOYeZvJ5FfrMfLfe7jUAkiC2N2Ybds2TJ8+umnGDx4sGnfY489hnbt2mHBggX4888/0bRpU3zwwQcs7KhS5ZdhOc0JUf0hk8nwamQgHDRKzPr9FOZsO4v8Ej3eeiQIcjmLOyJLYfa10ri4OAQHB9+yPzg4GHFxcQCAbt26ISUl5d7TkVXaw8KOqN56oVcLvDegDQBgaewFTF5/GAajWStPEpGEzC7smjRpgsWLF9+yf/HixfD19QUAZGZmws3N7d7TkdVJzy3GmfR8yGRARADH1xHVR9ERzfDpoA6Qy4B1+y9j3Kok6PRGqWMRUTWYfSn2k08+waBBg/Dbb7+hU6dOkMlk2LdvH06ePInvv/8eALBv3z5ERUXVeFiyfHvOlfXWtfVxgZsD76Amqq+eDG0CB40CL61Kwi9HUlGg02P+sFBoVZyvkag+M7vH7rHHHsOpU6fQr18/ZGVlISMjA/369cPJkyfxyCOPAACef/55fPbZZzUelizf7jNly4jxblii+q9v20b4ekQnaFVybD91HSO+2Yv8Er3UsYioCjIhBAdP1JLc3Fy4uLggJycHzs7OUseRnBACXWf+hdScYnz7XGd0b9lA6khEVA17k7Pw3NJ9yCvRo4OvK5Y90wmu9uxxJ6or5tQTZl+KBYDs7Gzs3bsX6enpMBorjrsYPnz43RySbMD5jAKk5hRDrZSjUzN3qeMQUTV19nfHd6O7YPg3CTh0KRtRC+Lx7ajOaOjE9ZGJ6huzC7uff/4ZTz/9NAoKCuDk5FRhjiOZTMbCjm6r/G7Y0KZuHKdDZGHaNXHBmrERGPZ1Ak5dy0PUgnisGBWOxq52Ukcjon8we4zdyy+/jGeffRZ5eXnIzs7GjRs3TFtWVlZtZCQrUV7YdWvJaU6ILNF9Xk5YFxOBJm52SM4owKB5sTh/PV/qWET0D2YXdleuXMG4ceNgb88VA6j6DEaBuHM3b5xozhsniCyVn4cD1sVEoHkDB1zNKcbgBfE4kVr5GuJEVPfMLuwiIyORmJhYG1nIih25koPcYj2ctEq0b+IqdRwiugeNXOywZmwEgho5IyO/BEMWxiMp5YbUsYgIdzHG7uGHH8arr76K48ePo127dlCpVBUef+yxx2osHFmP8suwEQEeUHB5IiKL5+mowaoxXfDMkr04kJKNYV8n4OsRnRDBHnkiSZk93YlcfvtOPplMBoPBcM+hrAWnO/nbU4viEXsuE+881gYjujaTOg4R1ZCCEj3GfJuIPWczoVHKMX9YKB4IbCh1LCKrYk49YfalWKPReNuNRR1VprjUgMSLZZdpuD4skXVx0CixeEQnPNTaCyV6I0YvT8Smw1eljkVks8wu7IjMlXjhBnR6I7ydtWjewEHqOERUw7QqBeYNC8FjHXygNwqMW5WEtfsuSR2LyCZVa4zd7NmzMWbMGGi1WsyePbvKtuPGjauRYGQ9dt8cX9e1hUeFeQ+tQkEB0KxZ2dcXLgAOLFzJNqkUcnwe1REOGgVW7b2E19YfRn6JHs9285c6GpFNqVZh9/nnn+Ppp5+GVqvF559/ftt2MpmMhR3dIvbczfnrrPUybEaG1AmI6gWFXIYPH28HR40Si3Yl491Nx1FQoseLD7awvj/qiOqpahV2ycnJlX5NdCfZhTocuZIDgOPriGyBTCbDlP6t4ahR4fOtp/HpltPIL9Hj9X6BLO6I6gDH2FGtijuXCSGAFg0d4eXMdSWJbIFMJsP4h1rizYdbAwAW7DyPNzcehdFo1iQMRHQXzJ7HzmAwYOnSpfjzzz+Rnp4Oo9FY4fG//vqrxsKR5dtj7Zdhiei2RnUPgKNGiTc2HMHKhBQU6gz4+L/toVSwT4Gotphd2I0fPx5Lly7Fww8/jLZt27Jrnaq05yyXESOyZUM6N4W9RolJaw5iQ9IVFJTo8X9PBUOjVEgdjcgqmV3YrV69GmvXrkX//v1rIw9ZkSvZRUjOKIBcBnRhYUdksx7r4AN7lQIvfHcAm49fw6hliVgQHQp7tdm/gojoDszuD1er1WjRokVtZCErU76MWAdfVzhrVXdoTUTW7KEgLywZ2Qn2agV2nclA9OK9yCkqlToWkdUxu7B7+eWX8eWXX8LMlcjIBpUXdvc35/g6Iiq7M/7b58LhrFVi/8UbeGpRPDLzS6SORWRVzO4H3717N7Zt24bffvsNbdq0gUpVsSfmhx9+qLFwZLmEEKbxdZzmhIjKhfq5YdWYLhi+eC+OXc1F1MJ4rHguHN4uvGueqCaYXdi5urri8ccfr40sZEVOX8tHRn4JtCo5QvxcpY5Te1Qq4O23//6aiO6ojY8L1oyNQPTiBJxNz8egBbH4blQX+LrbSx2NyOKZVdjp9Xr06tULkZGR8Pb2rq1MZAXKlxHr1Mzduu9+U6uB6dOlTkFkcVo0dMTasREYtjgBFzML8d/5sVg5KhwtGjpJHY3Iopk1xk6pVOL5559HSQnHRFDVYs9y/joiqpqvuz3WjY3AfV6OuJZbgsEL4nH05ko1RHR3zL55Ijw8HElJSbWRhaxEqcGI+PMcX0dEd9bQWYs1YyLQvokLsgp0GLooHokXsqSORWSxzB5j98ILL+Dll1/G5cuXERoaCgcHhwqPt2/fvsbCkWU6fDkbBToDXO1VCGrkLHUcIqrn3BzUWDkqHM8tTcTeC1mIXrwXi4aHoVtL/mFIZC6ZMHPeErn81k4+mUwGIQRkMhkMBkONhbN0ubm5cHFxQU5ODpydbafA+XLrGXy+9TQebtcIXz0dInUcIrIQRToDxq7Yj52nr0OtkGPOU8Ho04bjuYnMqSfM7rFLTk6+62BkG8rnr+vagqtNEFH12akVWDQ8FBNWH8RvR9Pw/MoD+HRQBwwMbix1NCKLYXZh5+fnVxs5yEoUlOiRdOkGAN44QUTm0ygV+L+hwXht/WH8cOAKJq49iAKdHk+H83cPUXXc9UJ9x48fR0pKCnQ6XYX9jz322D2HIsu190IWSg0CTdzs0JRzUhHRXVAq5Pjkvx3gqFFiedxFTN1wFAUleozp0VzqaET1ntmF3fnz5/H444/jyJEjprF1QNk4OwAcY2fj9pz5exmx8p8JIiJzyeUyvPNYGzhqlJi7/Rw+/PUk8ov1mNj7Pv7bQlQFs6c7GT9+PPz9/XHt2jXY29vj2LFj2LlzJ8LCwrB9+/ZaiEiWZM+5m9Oc8G42IrpHMpkMr/UNxKuRrQAAs/86i/c2neBa5URVMLuwi4uLw7vvvosGDRpALpdDLpejW7dumDFjBsaNG1cbGclCZOSX4ERqLgCga3PeOEFENeN/D7TAuwPaAAC+2ZOM19cfgcHI4o6oMmYXdgaDAY6OjgAAT09PXL16FUDZTRWnTp2q2XRkUWJv9tYFejvB01EjcRoisibDI5rhk0EdIJcBaxIvYfzqJOj0RqljEdU7Zo+xa9u2LQ4fPoyAgACEh4dj1qxZUKvVWLhwIQICAmojI1kILiNGRLXpv6FN4KBWYNzqJGw6nIpCnQFznw6BVmXF61ETmcnsHrs333wTRmPZX0nvv/8+Ll68iO7du+PXX3/F7NmzazwgWQYhBHaV3zjB8XVEVEv6tWuERcPDoFXJ8dfJdDyzZB/yS/RSxyKqN8xeeaIyWVlZcHNz451K/2JLK09czCxAz4+3QymX4dDbfeCgueuZdIiI7ijhfCaeW5aI/BI9Ovq6YukzneBqr5Y6FlGtMKeeMLvHrtzZs2fxxx9/oKioCO7u7nd7GLISe86Wja8LaerGoo6Ial14gAe+Gx0OV3sVDl7KxpCF8bieVyJ1LCLJmV3YZWZm4j//+Q/uu+8+9O/fH6mpqQCAUaNG4eWXXzY7wNy5c+Hv7w+tVovQ0FDs2rWryvY7duxAaGgotFotAgICMH/+/FvarF+/HkFBQdBoNAgKCsKGDRvu6bxjx46FTCbDF198YfbrsxXly4jdz/F1RFRH2jdxxZoxEWjgpMHJtDwMXhCHK9lFUscikpTZhd3EiROhUqmQkpICe/u/VxaIiorC77//btax1qxZgwkTJmDq1KlISkpC9+7d0a9fP6SkpFTaPjk5Gf3790f37t2RlJSEKVOmYNy4cVi/fr2pTVxcHKKiohAdHY1Dhw4hOjoagwcPRkJCwl2dd+PGjUhISICPj49Zr82WGI0CsefKCztOc0JEdaeVtxPWjY1AY1c7JGcUYPD8OCRnFEgdi0g6wkxeXl7i4MGDQgghHB0dxblz54QQQpw/f144ODiYdazOnTuLmJiYCvsCAwPF66+/Xmn71157TQQGBlbYN3bsWNGlSxfT94MHDxZ9+/at0CYyMlIMGTLE7PNevnxZNG7cWBw9elT4+fmJzz//vNqvTQghcnJyBACRk5Nj1vMszZHL2cJv8iYRNO03odMbpI5DRDboyo1C8cDH24Tf5E0i9L0t4kSqdf+7S7bFnHrC7B67goKCCj115TIyMqDRVH/uMp1Oh/3796NPnz4V9vfp0wexsbGVPicuLu6W9pGRkUhMTERpaWmVbcqPWd3zGo1GREdH49VXX0WbNm2q9ZpKSkqQm5tbYbMF5ZdhuwR4QKW462GbRER3zcfVDmvGRqB1I2dk5JdgyMJ4HLqULXUsojpn9m/hHj16YPny5abvZTIZjEYjPv74YzzwwAPVPk5GRgYMBgO8vLwq7Pfy8kJaWlqlz0lLS6u0vV6vR0ZGRpVtyo9Z3fN+9NFHUCqVZq2mMWPGDLi4uJg2X1/faj/Xku2+Wdh1tcXxdcXFwKBBZVtxsdRpiGxaAycNVo/ugo6+rsguLMVTi+IRfz5T6lhEdcrswu7jjz/GggUL0K9fP+h0Orz22mto27Ytdu7ciY8++sjsAP+eIkUIUeW0KZW1//f+6hyzqjb79+/Hl19+iaVLl5o1hcsbb7yBnJwc03bp0qVqP9dSlegN2HchC4CNTkxsMADff1+2GQxSpyGyeS72KqwcFY6IAA8U6AwY8c1ebDuVLnUsojpjdmEXFBSEw4cPo3PnzujduzcKCgrwxBNPICkpCc2bN6/2cTw9PaFQKG7pnUtPT7+lN62ct7d3pe2VSiU8PDyqbFN+zOqcd9euXUhPT0fTpk2hVCqhVCpx8eJFvPzyy2jWrNltX5NGo4Gzs3OFzdoduJiN4lIjPB01uM/LUeo4RERw0Cix5JlO+E9gQ5TojRizPBG/HE6VOhZRnbirAVHe3t545513sGnTJvz66694//33odfr8eyzz1b7GGq1GqGhodiyZUuF/Vu2bEHXrl0rfU5ERMQt7Tdv3oywsDCoVKoq25QfszrnjY6OxuHDh3Hw4EHT5uPjg1dffRV//PFHtV+jLfh7mhMPTlBNRPWGVqXA/OhQPNK+EUoNAi+tOoC1idZ/FYWoxmaSzcrKwrJly/DNN99U+zmTJk1CdHQ0wsLCEBERgYULFyIlJQUxMTEAyi5tXrlyxTSmLyYmBnPmzMGkSZMwevRoxMXFYfHixVi1apXpmOPHj0ePHj3w0UcfYcCAAfjxxx+xdetW7N69u9rn9fDwMPUAllOpVPD29karVq3u+j2yRnvOcf46IqqfVAo5vhwSDAe1EmsSL+G17w+jsESPkff7Sx2NqNZIukRAVFQUMjMz8e677yI1NRVt27bFr7/+Cj8/PwBAampqhbnl/P398euvv2LixIn46quv4OPjg9mzZ+PJJ580tenatStWr16NN998E9OmTUPz5s2xZs0ahIeHV/u8VD25xaWmu85Y2BFRfaSQyzDzyXZw0CjxzZ5kTP/5OAp0BrzQqzmvMpBVqpG1YgHg0KFDCAkJgYEDyE2sfa3YLcevYfTyRPh7OmDbK72kjiONggLA8ebYwvx8wMFB2jxEVCkhBD7fegaz/zwDAIjp2RyT+7ZicUcWoU7WiiX65/g6IqL6TCaTYVLv+zClfyAAYP6Oc5j241EYjTXSt0FUb1T7UuwTTzxR5ePZ2dn3moUsTPn8dTY5zQkRWaQxPZrDUaPC1I1HsCI+BYUlBsz6b3soObk6WYlqF3YuLi53fHz48OH3HIgsw7XcYpxNz4dMVrbiBBGRpXgqvCkcNApMWnsIPyRdQYFOj9lDg6FRKqSORnTPql3YLVmypDZzkIUpvwzbrrELXO3VEqeRkFwO9Oz599dEZBEGdGwMe7US/1t5AH8cu4ZRyxKxMDoMdmoWd2TZ+JuI7sqes2XL9Nj83bB2dsD27WWbnZ3UaYjIDL2DvPDNyE6wUymw60wGhn+TgNziUqljEd0TFnZkNiHE3zdONLfxwo6ILFq3lp5YMaoznLRK7LtwA08vSkBWgU7qWER3jYUdme3c9QKk5RZDrZQjrJmb1HGIiO5JqJ87Vo/pAg8HNY5cyUHUgjhcyy2WOhbRXWFhR2aLvbnaRKdmbtCqOB6FiCxfGx8XrBkbAW9nLc6k52PQ/DhcyiqUOhaR2VjYkdl2nykr7LryMiwRWZEWDR2xLiYCTd3tkZJViEHz43A2PV/qWERmYWFHZtEbjIg7X3bjBOevIyJr4+tuj3UxEWjZ0BFpucWIWhCHo1dypI5FVG0s7MgsR6/mIq9YD2etEm0bVz23IRGRJfJy1mLN2Ai0a+yCzAIdhi6Kx/6LWVLHIqoWFnZklvK7YSOae0Ah5xqLRGSd3B3UWDk6HJ2auSGvWI9hX+81DUMhqs9Y2JFZ/l4flpdhici6OWtVWP5sOLq39ERRqQHPLt2HLcevSR2LqEos7KjainQGJF64AYDj64jINtipFfh6RBgi23hBZzAiZsV+/HjwitSxiG6LhR1VW+LFLOgMRjRy0cLf00HqOEREdUKjVOCrp0LwRHBjGIwCE9YcxHcJKVLHIqoUCzuqtn8uIyaTcXwdEdkOpUKOTwZ1wLAuTSEEMGXDESzaeV7qWES3YGFH1fb3+DoPiZMQEdU9uVyG9wa0RUzP5gCAD349gc+3nIYQQuJkRH9jYUfVkl2ow9GrZXM5cX1YIrJVMpkMr/cLxKuRrQAAX/55Bu//coLFHdUbLOyoWuLOZUII4D4vRzR01kodh4hIUv97oAWmPxoEAFi8Oxlv/HAEBiOLO5IeCzuqlt1nuYwYEdE/jbzfH7P+2x5yGbB63yWMX52EUoNR6lhk41jYUbWUj6/jNCdERH8bHOaL/xsaApVChk2HUxHz7X4UlxqkjkU2jIUd3dHlG4W4kFkIhVyG8AB3qeMQEdUrD7dvhIXRYdAo5fjzZDqeXboPBSV6qWORjWJhR3cUe3Oakw5NXOCkVUmchoio/nkgsCGWPdsZDmoFYs9lYtjiBOQUlkodi2wQCzu6o928DEtEdEddAjywcnQXuNipkJSSjSGL4pGRXyJ1LLIxLOyoSkIIxJ67eeMEC7tblZYCX31VtpXyr3MiW9fR1xVrxnaBp6MGJ1JzMXhBHK5mF0kdi2wICzuq0qlrecjI18FOpUBwU1ep49Q/Oh3w4otlm04ndRoiqgcCvZ2xLiYCjV3tcP56AQbNj8PFzAKpY5GNYGFHVdp9pqy3rrO/OzRKhcRpiIgsg7+nA9bGRCDA0wFXsoswaH4cTl/LkzoW2QAWdlQlLiNGRHR3GrvaYc3YCAR6OyE9rwSDF8Th8OVsqWORlWNhR7dVajAiITkLAHA/x9cREZmtgZMGq8d0QUdfV2QXluKpRQnYe/PfVaLawMKObuvgpWwU6gxwd1Cjtbez1HGIiCySq70aK0aFo0uAO/JL9Bj+TQK2n0qXOhZZKRZ2dFvl4+siAjwgl8skTkNEZLkcNUosfaYzHgxsiOJSI0YvT8RvR1KljkVWiIUd3Vb5NCfdWvIyLBHRvdKqFJg/LBQPt2+EUoPA/747gPX7L0sdi6wMCzuqVEGJHkkp2QCA+5uzsCMiqglqpRyzhwRjcFgTGAXw8rpD+DbugtSxyIqwsKNK7U3Ogt4o4Otuh6Ye9lLHISKyGgq5DDOfaI9n7m8GAJj24zHM3X5W2lBkNVjYUaW4jBgRUe2Ry2V465EgjHuwBQBg1u+nMOv3kxBCSJyMLB0LO6pU+fx1XXkZtmoODoAQZZuDg9RpiMiCyGQyTOrTClP6BwIA5m4/h+k/HYPRyOKO7h4LO7rF9bwSnEwrmyG9a3NOTExEVJvG9GiODx5vC5kMWBZ3Ea9+fxh6g1HqWGShWNjRLcrvhg1q5AwPR43EaYiIrN/T4X74fHBHKOQyrD9wGS+tSkKJ3iB1LLJALOzoFrFnMwFwGTEioro0MLgx5j4dArVCjt+OpmH08v0o0rG4I/OwsKMKhBCmGye4jBgRUd2KbOONxSPDYKdSYOfp6xjxzV7kFZdKHYssCAs7quBiZiGuZBdBpZChs7+71HGIiGxO95YN8O1zneGkUWLvhSw8/XUCbhTopI5FFoKFHVWw5+b4upCmbrBXKyVOQ0Rkm8KauWPVmC5ws1fh8OUcRC2MQ3pusdSxyAKwsKMK9vAyLBFRvdC2sQvWjo2Al7MGp6/lY9CCOFzKKpQ6FtVzLOzIxGgUiD1XfuMECzsiIqm19HLCurFd4etuh4uZhRi8IA5n0/OljkX1GAs7MjmemovswlI4apTo0MRF6jhERASgqYc91o3tihYNHZGaU4yoBXE4fjVX6lhUT7GwI5Pyu2G7BLhDqeCPBhFRfeHtosWaMV3QxscZmQU6DFkYhwMpN6SORfUQf3uTCcfXERHVXx6OGnw3ugvC/NyQW6zHsK8TEHvz322icizsCABQXGrAvgtZAIBuLOyIiOolFzsVlj/XGd1beqJQZ8DIpfvw54lrUseieoSFHQEADqTcQHGpEQ2dNGjR0FHqOEREdBv2aiW+HhGGPkFe0OmNGPvtfvx06KrUsaieYGFHAP5eRqxrcw/IZDKJ0xARUVU0SgW+ejoEAzv6QG8UGL86Cav3pkgdi+oBFnYEAFxGjIjIwqgUcnw2uCOeDm8KIYDXfziCxbuTpY5FEmNhR8gpKsXhy9kAWNgREVkSuVyG9we2xdgeAQCA9zYdx5dbz0AIIXEykgoLO0LC+UwYBRDQwAE+rnZSxyEiIjPIZDK83i8QL/e+DwDw+dbT+PDXEyzubBQLO/p7mpPm7K0jIrJEMpkML/2nJd56JAgAsGhXMqZsOAqDkcWdrWFhRxxfR0RkJZ7t5o9ZT7aHXAas2puCSWsPotRglDoW1SEWdjYuLacY564XQC4DIgI8pI5jeYxG4Nixss3IfzyJSHqDO/li9tBgKOUy/HjwKp5fcQDFpQapY1EdYWFn48ovw7Zr7AIXe5XEaSxQURHQtm3ZVlQkdRoiIgDAI+19sHB4KDRKObaeuIbnlu1DQYle6lhUB1jY2TguI0ZEZJ0eDPTC0mc6w0GtwJ6zmYhenICcolKpY1EtY2Fnw4QQ2HOOhR0RkbWKaO6BlaO7wMVOhQMp2Ri6MB4Z+SVSx6JaxMLOhp27no9ruSXQKOUI9XOTOg4REdWCjr6uWD2mCzwdNTiemouoBXFIzeHQEWvFws6G7T5T1lvXqZk7tCqFxGmIiKi2tG7kjLVju8DHRYtz1wswaH4cLmYWSB2LagELOxu259zN9WFb8G5YIiJrF9DAEWtjItDMwx6XbxRh0Pw4nL6WJ3UsqmEs7GyU3mBE/M3CrhvH1xER2YQmbvZYOzYCrbyckJ5XgqgFcThyOUfqWFSDJC/s5s6dC39/f2i1WoSGhmLXrl1Vtt+xYwdCQ0Oh1WoREBCA+fPn39Jm/fr1CAoKgkajQVBQEDZs2GDWeUtLSzF58mS0a9cODg4O8PHxwfDhw3H16tV7f8H1xOErOcgr0cNZq0QbHxep4xARUR1p6KzF6jFd0KGJC24UluKpRfHYm5wldSyqIZIWdmvWrMGECRMwdepUJCUloXv37ujXrx9SUlIqbZ+cnIz+/fuje/fuSEpKwpQpUzBu3DisX7/e1CYuLg5RUVGIjo7GoUOHEB0djcGDByMhIaHa5y0sLMSBAwcwbdo0HDhwAD/88ANOnz6Nxx57rHbfkDoUe3Oak67NPaGQyyROQ0REdcnNQY0Vo8LR2d8deSV6DP8mATtPX5c6FtUAmZBwleDw8HCEhIRg3rx5pn2tW7fGwIEDMWPGjFvaT548GT/99BNOnDhh2hcTE4NDhw4hLi4OABAVFYXc3Fz89ttvpjZ9+/aFm5sbVq1adVfnBYB9+/ahc+fOuHjxIpo2bVqt15ebmwsXFxfk5OTA2dm5Ws+pK0MWxiH+fBbeG9gW0V38pI5juQoKAEfHsq/z8wEHB2nzEBGZoUhnwPMr92P7qetQK+SYPTQYfdt6Sx2L/sWcekKyHjudTof9+/ejT58+Ffb36dMHsbGxlT4nLi7ulvaRkZFITExEaWlplW3Kj3k35wWAnJwcyGQyuLq63rZNSUkJcnNzK2z1UZHOgAMXswEA9zfnjRP3RKsFtm0r27RaqdMQEZnFTq3Awugw9G/nDZ3BiP99dwA/HLgsdSy6B5IVdhkZGTAYDPDy8qqw38vLC2lpaZU+Jy0trdL2er0eGRkZVbYpP+bdnLe4uBivv/46nnrqqSor5RkzZsDFxcW0+fr63ratlPZdyILOYEQjFy38PdnDdE8UCqBXr7JNwSljiMjyqJVyzB4SjP+GNoHBKDBp7SF8G39R6lh0lyS/eUImqzi+Swhxy747tf/3/uocs7rnLS0txZAhQ2A0GjF37twqXgnwxhtvICcnx7RdunSpyvZSKV9GrFsLzyrfayIisg1KhRyznmyPkV2bAQCmbTyK+TvOSRuK7opSqhN7enpCoVDc0kuWnp5+S29aOW9v70rbK5VKeHh4VNmm/JjmnLe0tBSDBw9GcnIy/vrrrzte19ZoNNBoNFW2qQ+4jBgREf2bXC7D248GwVGjxJxtZzHzt5PIL9bj5T73sRPAgkjWY6dWqxEaGootW7ZU2L9lyxZ07dq10udERETc0n7z5s0ICwuDSqWqsk35Mat73vKi7syZM9i6daupcLR0WQU6HLtaNvaPExMTEdE/yWQyvBLZCpP7BgIA5mw7i3d+Pg6jUbL7LMlMkvXYAcCkSZMQHR2NsLAwREREYOHChUhJSUFMTAyAskubV65cwfLlywGU3QE7Z84cTJo0CaNHj0ZcXBwWL15sutsVAMaPH48ePXrgo48+woABA/Djjz9i69at2L17d7XPq9fr8d///hcHDhzApk2bYDAYTD187u7uUKvVdfUW1bi4c5kQAmjl5YSGThzsT0REt3q+V3M4ahSY9uMxLI29gIISPWY+2Z7TY1kASQu7qKgoZGZm4t1330Vqairatm2LX3/9FX5+ZdNvpKamVpjTzt/fH7/++ismTpyIr776Cj4+Ppg9ezaefPJJU5uuXbti9erVePPNNzFt2jQ0b94ca9asQXh4eLXPe/nyZfz0008AgI4dO1bIvG3bNvTq1auW3pHaV34Zlr11RERUleiIZnDQKPHKukNYt/8yCnUGfB7VEWql5MPzqQqSzmNn7erjPHY9P96Gi5mFWDwiDP9pXflYRiIionK/H03FS6uSUGoQ6NWqAeYPC4VWxVkA6pJFzGNHde9SViEuZhZCIZchPIA9dkREdGd92zbC1yM6QauSY/up6xjxzV7kl+iljkW3wcLOhsTevAzb0dcVjhpJr8ITEZEF6XlfA3z7XDicNEokJGfh6a8TkF2okzoWVYKFnQ3ZfTYTAKc5ISIi83Vq5o7vRneBm70Khy5lI2pBPNLziqWORf/Cws5GGI0Csf+YmJiIiMhc7Zq4YO3YCDR00uDUtTwMnh+HyzcKpY5F/8DCzkacupaHzAId7FQKdPR1lToOERFZqJZeTvg+piuauNnhQmYhBs+Pw/nr+VLHoptY2NmI8mXEwgPceas6ERHdk6Ye9lgXE4HmDRxwNacYgxfE4URqrtSxCCzsbMYeXoYlIqIa1MjFDmvGRiCokTMy8nWIWhCHpJQbUseyeSzsbIBOb0RCchYAoGtzFnZERFQzPB01WDWmC0KauiK3WI9hXycg7lym1LFsGgs7G3DocjYKdQZ4OKgR6O0kdRwiIrIiLnYqfPtcOO5v4YECnQEjl+zFXyevSR3LZrGwswG7z5QvI+YJOdf5IyKiGuagUWLxiE54qLUXSvRGjFm+H5sOX5U6lk1iYWcDysfX3d+cq00QEVHt0KoUmDcsBI918IHeKDBuVRLW7rskdSybw8LOyuWX6HHwUjYATkxMRES1S6WQ4/Oojhja2RdGAby2/jC+2Z0sdSybwsLOyu1NzoTeKNDU3R6+7vZSxyEiIiunkMvw4ePtMLq7PwDg3U3H8X9/noEQQuJktoGFnZXbw2XEaldBAdCgQdlWUCB1GiKiekEmk2FK/9aY+NB9AIBPt5zGzN9OsrirAyzsrBznr6sDGRllGxERmchkMox/qCXefLg1AGDBzvN4c+NRGI0s7moTCzsrlp5XjJNpeQCACN44QUREEhjVPQAznmgHmQxYmZCCSWsPotRglDqW1WJhZ8XKJ4ls4+MMdwe1xGmIiMhWDe3cFF8OCYZSLsPGg1fxwsoDKC41SB3LKrGws2K8DEtERPXFYx18MH9YKNRKObYcv4ZRyxJRqNNLHcvqsLCzUkKIChMTExERSe2hIC8sHdkJ9moFdp/NQPTivcgpKpU6llVhYWelLmQW4mpOMdQKOTo1c5M6DhEREYCyzoYVo8LhrFVi/8UbGLowHpn5JVLHshos7KxU+WXY4KausFcrJU5DRET0t5Cmblg1pgs8HNQ4npqLwQvikJZTLHUsq8DCzkpxfB0REdVnbXxcsDYmAo1ctDh3vQCDFsQiJbNQ6lgWj4WdFTIYBWJv3hF7f0sWdkREVD81b+CIdTER8POwx6WsIgxaEIsz1/KkjmXRWNhZoeNXc5FTVAonjRLtG7tIHce6qVTA22+XbSqV1GmIiCxOEzd7rBsbgfu8HHEttwRRC+Nx9EqO1LEsFgs7K7T75mXY8AAPKBX8iGuVWg1Mn162qTlXIBHR3WjorMWaMRFo38QFWQU6DF0Yj8QLWVLHskj8rW+FysfX3d+Cq00QEZFlcHNQY+WocHT2d0deiR7Ri/di15nrUseyOCzsrExxqQH7bv6VwxsniIjIkjhpVVj2TGf0vK8BikoNeG5pIv44liZ1LIvCws7KHLh4AyV6Ixo6adCioaPUcYiIiMxip1Zg0fAw9GvrDZ3BiBdWHsDGpCtSx7IYLOyszG7TZVhPyGQyidMQERGZT62U4/+GBuPJkCYwGAUmrj2IlQkXpY5lEVjYWZk95dOc8DIsERFZMKVCjo//2x4jIvwgBDB1w1Es2HFO6lj1Hgs7K5JTWIojl7MB8MYJIiKyfHK5DNMfa4MXejUHAMz47SQ+3XwKQgiJk9VfLOysSNz5TBgFENDAAY1c7KSOQ0REdM9kMhle6xuI1/q2AgD8319n8e6m4zAaWdxVhoWdFYk9x2XEiIjIOr3QqwXeG9AGALBkzwW8/sNhGFjc3YKFnRUpv3Gia3MWdkREZH2iI5rh00EdIJcBaxMvY9zqJOj0Rqlj1Sss7KxEak4Rzl8vgFwGRARwfB0REVmnJ0Ob4KunQqBSyPDL4VTErNiP4lKD1LHqDRZ2VmLP2bK7Yds1cYWLPdcsJSIi69WvXSN8PaITtCo5/jqZjpFL9iK/RC91rHqBhZ2VMC0j1py9dUREZP163tcAy58Nh6NGifjzWXj66wRkF+qkjiU5FnZWQAhhGl/HGyeIiMhWdPZ3x3ejw+Fqr8KhS9kYsjAe6XnFUseSFAs7K3A2PR/X80qgUcoR4ucmdRwiIqI6076JK9aMiUADJw1OpuUhakE8rmQXSR1LMizsrEB5b12nZu7QqhQSpyEiIqpbrbydsG5sBBq72iE5owCD5sUiOaNA6liSYGFnBfb8Y31YIiIiW9TM0wHrYiIQ4OmAqznFGDQ/DifTcqWOVedY2Fk4vcGI+PNZADi+joiIbJuPqx3WjI1A60bOyMgvQdSCeBy8lC11rDrFws7CHbqcg/wSPVztVQjycZY6DhERkaQaOGmwenQXBDd1RU5RKZ5eFI/485lSx6ozLOwsXPll2IgADyjkMonTEBERSc/FXoUVz4Wja3MPFOgMGPHNXmw7mS51rDrBws7CcXydxIqLgUGDyrZi277FnoioPnHQKPHNyE54qHVDlOiNGPNtIn45nCp1rFrHws6CFer0OJByAwDH10nGYAC+/75sM3BJGyKi+kSrUmDesFA82sEHpQaBl1YdwNrES1LHqlUs7CzY3uQslBoEGrvawc/DXuo4RERE9Y5KIccXUR0xpJMvjAJ47fvDWLonWepYtYaFnQWLPVc2GPT+Fh6QyTi+joiIqDIKuQwznmiH57r5AwCm/3wcc/46AyGExMlqHgs7C7b7DMfXERERVYdMJsObD7fG+P+0BAB8svk0Pvr9lNUVdyzsLJTBKBDYyAlezhp0bc7CjoiI6E5kMhkm9r4PU/u3BgDM33EO0348CqPReoo7pdQB6O4o5DJ8NrgjhBC8DEtERGSG0T0C4KBRYurGI1gRn4LCEgNm/bc9lArL7++y/Fdg41jUERERme+p8Kb4IqojFHIZfki6gv99dwAlesuf3YCFHREREdmkAR0bY/6wUKiVcvxx7BpGLUtEkc6yizsWdkRERGSzegd5YcnITrBXK7DrTAaGf5OA3OJSqWPdNRZ2RPdCLgd69izb5PzfiYjIEt3fwhPfPhcOJ60S+y7cwFOL4pFVoJM61l3hbyKie2FnB2zfXrbZ2UmdhoiI7lKonxtWj+kCDwc1jl7JRdSCOFzLtbylIlnYEREREQFo4+OCNWMj4O2sxZn0fAyaH4dLWYVSxzILCzsiIiKim1o0dMS6mAg0dbdHSlYhBs2Pw9n0PKljVRsLOyIiIqJ/8HW3x7qYCLRs6Ii03GIMXhCPo1dypI5VLSzsiIiIiP7Fy1mLNWMj0K6xC7IKdBi6KB77L2ZJHeuOWNgRERERVcLdQY2Vo8PRqZkb8or1GPb1XtM67fUVCzsiIiKi23DWqrD82XB0b+mJolIDnl26D5uPpUkd67ZY2BERERFVwU6twNcjwhDZxgs6gxHPrzyAHw9ekTpWpSQv7ObOnQt/f39otVqEhoZi165dVbbfsWMHQkNDodVqERAQgPnz59/SZv369QgKCoJGo0FQUBA2bNhg9nmFEJg+fTp8fHxgZ2eHXr164dixY/f2YomIiMgiaZQKfPVUCJ4IbgyDUWDCmoP4LiFF6li3kLSwW7NmDSZMmICpU6ciKSkJ3bt3R79+/ZCSUvkblZycjP79+6N79+5ISkrClClTMG7cOKxfv97UJi4uDlFRUYiOjsahQ4cQHR2NwYMHIyEhwazzzpo1C5999hnmzJmDffv2wdvbG71790ZenuXc8kxEREQ1R6mQ45NBHTCsS1MIAUzZcASLdp6XOlYFMiGEkOrk4eHhCAkJwbx580z7WrdujYEDB2LGjBm3tJ88eTJ++uknnDhxwrQvJiYGhw4dQlxcHAAgKioKubm5+O2330xt+vbtCzc3N6xatapa5xVCwMfHBxMmTMDkyZMBACUlJfDy8sJHH32EsWPHVuv15ebmwsXFBTk5OXB2djbjnSEiIqL6SgiBj34/hfk7zgEAxv2nJSY+1BIymaxWzmdOPSFZj51Op8P+/fvRp0+fCvv79OmD2NjYSp8TFxd3S/vIyEgkJiaitLS0yjblx6zOeZOTk5GWllahjUajQc+ePW+bDSgr/nJzcytsREREZF1kMhle7xeIVyNbAQBm/3kG7/9yAhL2lZlIVthlZGTAYDDAy8urwn4vLy+kpVV+t0laWlql7fV6PTIyMqpsU37M6py3/L/mZAOAGTNmwMXFxbT5+vreti0RERFZtv890ALTHw0CAPx2JBVZBTqJEwFKqQP8u9tSCFFlV2Zl7f+9vzrHrKk2//TGG29g0qRJpu9zc3NZ3BEREVmxkff7w9VejfZNXODhqJE6jnSFnaenJxQKxS09YOnp6bf0lJXz9vautL1SqYSHh0eVbcqPWZ3zent7AyjruWvUqFG1sgFll2s1Guk/VCIiIqo7A4MbSx3BRLJLsWq1GqGhodiyZUuF/Vu2bEHXrl0rfU5ERMQt7Tdv3oywsDCoVKoq25Qfszrn9ff3h7e3d4U2Op0OO3bsuG02IiIiIskJCa1evVqoVCqxePFicfz4cTFhwgTh4OAgLly4IIQQ4vXXXxfR0dGm9ufPnxf29vZi4sSJ4vjx42Lx4sVCpVKJ77//3tRmz549QqFQiJkzZ4oTJ06ImTNnCqVSKeLj46t9XiGEmDlzpnBxcRE//PCDOHLkiBg6dKho1KiRyM3Nrfbry8nJEQBETk7OvbxNREREZMPMqSckLeyEEOKrr74Sfn5+Qq1Wi5CQELFjxw7TYyNGjBA9e/as0H779u0iODhYqNVq0axZMzFv3rxbjrlu3TrRqlUroVKpRGBgoFi/fr1Z5xVCCKPRKN5++23h7e0tNBqN6NGjhzhy5IhZr42FHREREd0rc+oJSeexs3acx46IiIjulUXMY0dERERENUvy6U6ILFppKbBwYdnXY8YAN2/iISIikgILO6J7odMBL75Y9vXIkSzsiIhIUrwUS0RERGQlWNgRERERWQkWdkRERERWgoUdERERkZVgYUdERERkJVjYEREREVkJFnZEREREVoKFHREREZGV4ATFtah8Gd7c3FyJk1CtKSj4++vcXMBgkC4LERFZpfI6oryuqAoLu1qUl5cHAPD19ZU4CdUJHx+pExARkRXLy8uDi4tLlW1kojrlH90Vo9GIq1evwsnJCTKZrMaPn5ubC19fX1y6dAnOzs41fnyqHn4O9QM/B+nxM6gf+DnUDzX5OQghkJeXBx8fH8jlVY+iY49dLZLL5WjSpEmtn8fZ2Zn/89YD/BzqB34O0uNnUD/wc6gfaupzuFNPXTnePEFERERkJVjYEREREVkJFnYWTKPR4O2334ZGo5E6ik3j51A/8HOQHj+D+oGfQ/0g1efAmyeIiIiIrAR77IiIiIisBAs7IiIiIivBwo6IiIjISrCws2Bz586Fv78/tFotQkNDsWvXLqkjWa0ZM2agU6dOcHJyQsOGDTFw4ECcOnWqQhshBKZPnw4fHx/Y2dmhV69eOHbsmESJrd+MGTMgk8kwYcIE0z5+BnXjypUrGDZsGDw8PGBvb4+OHTti//79psf5OdQ+vV6PN998E/7+/rCzs0NAQADeffddGI1GUxt+DjVv586dePTRR+Hj4wOZTIaNGzdWeLw673lJSQleeukleHp6wsHBAY899hguX75ccyEFWaTVq1cLlUolFi1aJI4fPy7Gjx8vHBwcxMWLF6WOZpUiIyPFkiVLxNGjR8XBgwfFww8/LJo2bSry8/NNbWbOnCmcnJzE+vXrxZEjR0RUVJRo1KiRyM3NlTC5ddq7d69o1qyZaN++vRg/frxpPz+D2peVlSX8/PzEyJEjRUJCgkhOThZbt24VZ8+eNbXh51D73n//feHh4SE2bdokkpOTxbp164Sjo6P44osvTG34OdS8X3/9VUydOlWsX79eABAbNmyo8Hh13vOYmBjRuHFjsWXLFnHgwAHxwAMPiA4dOgi9Xl8jGVnYWajOnTuLmJiYCvsCAwPF66+/LlEi25Keni4AiB07dgghhDAajcLb21vMnDnT1Ka4uFi4uLiI+fPnSxXTKuXl5YmWLVuKLVu2iJ49e5oKO34GdWPy5MmiW7dut32cn0PdePjhh8Wzzz5bYd8TTzwhhg0bJoTg51AX/l3YVec9z87OFiqVSqxevdrU5sqVK0Iul4vff/+9RnLxUqwF0ul02L9/P/r06VNhf58+fRAbGytRKtuSk5MDAHB3dwcAJCcnIy0trcJnotFo0LNnT34mNex///sfHn74YTz00EMV9vMzqBs//fQTwsLCMGjQIDRs2BDBwcFYtGiR6XF+DnWjW7du+PPPP3H69GkAwKFDh7B79270798fAD8HKVTnPd+/fz9KS0srtPHx8UHbtm1r7HPhWrEWKCMjAwaDAV5eXhX2e3l5IS0tTaJUtkMIgUmTJqFbt25o27YtAJje98o+k4sXL9Z5Rmu1evVq7N+/H4mJibc8xs+gbpw/fx7z5s3DpEmTMGXKFOzduxfjxo2DRqPB8OHD+TnUkcmTJyMnJweBgYFQKBQwGAz44IMPMHToUAD8/0EK1XnP09LSoFar4ebmdkubmvr9zcLOgslksgrfCyFu2Uc178UXX8Thw4exe/fuWx7jZ1J7Ll26hPHjx2Pz5s3QarW3bcfPoHYZjUaEhYXhww8/BAAEBwfj2LFjmDdvHoYPH25qx8+hdq1ZswYrVqzAd999hzZt2uDgwYOYMGECfHx8MGLECFM7fg51727e85r8XHgp1gJ5enpCoVDcUt2np6ff8pcC1ayXXnoJP/30E7Zt24YmTZqY9nt7ewMAP5NatH//fqSnpyM0NBRKpRJKpRI7duzA7NmzoVQqTe8zP4Pa1ahRIwQFBVXY17p1a6SkpADg/wt15dVXX8Xrr7+OIUOGoF27doiOjsbEiRMxY8YMAPwcpFCd99zb2xs6nQ43bty4bZt7xcLOAqnVaoSGhmLLli0V9m/ZsgVdu3aVKJV1E0LgxRdfxA8//IC//voL/v7+FR739/eHt7d3hc9Ep9Nhx44d/ExqyH/+8x8cOXIEBw8eNG1hYWF4+umncfDgQQQEBPAzqAP333//LVP9nD59Gn5+fgD4/0JdKSwshFxe8Ve4QqEwTXfCz6HuVec9Dw0NhUqlqtAmNTUVR48erbnPpUZuwaA6Vz7dyeLFi8Xx48fFhAkThIODg7hw4YLU0azS888/L1xcXMT27dtFamqqaSssLDS1mTlzpnBxcRE//PCDOHLkiBg6dCinFqhl/7wrVgh+BnVh7969QqlUig8++ECcOXNGrFy5Utjb24sVK1aY2vBzqH0jRowQjRs3Nk138sMPPwhPT0/x2muvmdrwc6h5eXl5IikpSSQlJQkA4rPPPhNJSUmmqcaq857HxMSIJk2aiK1bt4oDBw6IBx98kNOdUJmvvvpK+Pn5CbVaLUJCQkxTb1DNA1DptmTJElMbo9Eo3n77beHt7S00Go3o0aOHOHLkiHShbcC/Czt+BnXj559/Fm3bthUajUYEBgaKhQsXVnicn0Pty83NFePHjxdNmzYVWq1WBAQEiKlTp4qSkhJTG34ONW/btm2V/i4YMWKEEKJ673lRUZF48cUXhbu7u7CzsxOPPPKISElJqbGMMiGEqJm+PyIiIiKSEsfYEREREVkJFnZEREREVoKFHREREZGVYGFHREREZCVY2BERERFZCRZ2RERERFaChR0RERGRlWBhR0RERGQlWNgRERERWQkWdkRENSQ9PR1jx45F06ZNodFo4O3tjcjISMTFxQEAZDIZNm7cKG1IIrJqSqkDEBFZiyeffBKlpaVYtmwZAgICcO3aNfz555/IysqSOhoR2QiuFUtEVAOys7Ph5uaG7du3o2fPnrc83qxZM1y8eNH0vZ+fHy5cuAAA+PnnnzF9+nQcO3YMPj4+GDFiBKZOnQqlsuxvb5lMhrlz5+Knn37C9u3b4e3tjVmzZmHQoEF18tqIyHLwUiwRUQ1wdHSEo6MjNm7ciJKSklse37dvHwBgyZIlSE1NNX3/xx9/YNiwYRg3bhyOHz+OBQsWYOnSpfjggw8qPH/atGl48skncejQIQwbNgxDhw7FiRMnav+FEZFFYY8dEVENWb9+PUaPHo2ioiKEhISgZ8+eGDJkCNq3bw+grOdtw4YNGDhwoOk5PXr0QL9+/fDGG2+Y9q1YsQKvvfYarl69anpeTEwM5s2bZ2rTpUsXhISEYO7cuXXz4ojIIrDHjoiohjz55JO4evUqfvrpJ0RGRmL79u0ICQnB0qVLb/uc/fv349133zX1+Dk6OmL06NFITU1FYWGhqV1ERESF50VERLDHjohuwZsniIhqkFarRe/evdG7d2+89dZbGDVqFN5++22MHDmy0vZGoxHvvPMOnnjiiUqPVRWZTFYTkYnIirDHjoioFgUFBaGgoAAAoFKpYDAYKjweEhKCU6dOoUWLFrdscvnf/0THx8dXeF58fDwCAwNr/wUQkUVhjx0RUQ3IzMzEoEGD8Oyzz6J9+/ZwcnJCYmIiZs2ahQEDBgAouzP2zz//xP333w+NRgM3Nze89dZbeOSRR+Dr64tBgwZBLpfj8OHDOHLkCN5//33T8detW4ewsDB069YNK1euxN69e7F48WKpXi4R1VO8eYKIqAaUlJRg+vTp2Lx5M86dO4fS0lJTsTZlyhTY2dnh559/xqRJk3DhwgU0btzYNN3JH3/8gXfffRdJSUlQqVQIDAzEqFGjMHr0aABll1y/+uorbNy4ETt37oS3tzdmzpyJIUOGSPiKiag+YmFHRFTPVXY3LRFRZTjGjoiIiMhKsLAjIiIishK8eYKIqJ7jiBkiqi722BERERFZCRZ2RERERFaChR0RERGRlWBhR0RERGQlWNgRERERWQkWdkRERERWgoUdERERkZVgYUdERERkJVjYEREREVmJ/wfLRX5YTHbIiQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_model = nn.Linear(2, 1)\n",
    "optimizer = AdamW(params=dummy_model.parameters(), lr=0.001)\n",
    "warmup_steps = 20\n",
    "total_training_steps = 100\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=warmup_steps,\n",
    "  num_training_steps=total_training_steps\n",
    ")\n",
    "learning_rate_history = []\n",
    "for step in range(total_training_steps):\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "  learning_rate_history.append(optimizer.param_groups[0]['lr'])\n",
    "plt.plot(learning_rate_history, label=\"learning rate\")\n",
    "plt.axvline(x=warmup_steps, color=\"red\", linestyle=(0, (5, 10)), label=\"warmup end\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 230)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing BertModel: ['roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'lm_head.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.key.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'embeddings.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ToxicCommentTagger(\n",
    "  n_classes=len(types),\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "prediction = torch.FloatTensor(\n",
    "  [10.95873564, 1.07321467, 1.58524066, 0.03839076, 15.72987556, 1.09513213]\n",
    ")\n",
    "labels = torch.FloatTensor(\n",
    "  [1., 0., 0., 0., 1., 0.]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.7452, 0.8299, 0.5096, 1.0000, 0.7493])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8725)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.sigmoid(prediction), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4396, 0.5189, 0.4877, 0.5319, 0.4142, 0.5191, 0.5478, 0.5132, 0.4922,\n",
       "         0.4821, 0.5069, 0.4351, 0.5166, 0.4892, 0.5289, 0.5514, 0.4543, 0.4614,\n",
       "         0.5138, 0.4859, 0.5183, 0.5720, 0.5185, 0.5012],\n",
       "        [0.4293, 0.5191, 0.4733, 0.5066, 0.3792, 0.5318, 0.5109, 0.5270, 0.5029,\n",
       "         0.4978, 0.5026, 0.4574, 0.5133, 0.4917, 0.5458, 0.5580, 0.4894, 0.4701,\n",
       "         0.5230, 0.4957, 0.4967, 0.5471, 0.4947, 0.4857],\n",
       "        [0.4490, 0.5285, 0.4779, 0.4969, 0.3734, 0.5361, 0.5189, 0.4860, 0.4717,\n",
       "         0.4661, 0.4895, 0.4693, 0.5247, 0.4625, 0.5293, 0.5525, 0.4897, 0.4457,\n",
       "         0.5160, 0.4887, 0.4972, 0.5476, 0.4932, 0.5001],\n",
       "        [0.4334, 0.5075, 0.4880, 0.4953, 0.3808, 0.5461, 0.5334, 0.5114, 0.4828,\n",
       "         0.4715, 0.4871, 0.4561, 0.5203, 0.4933, 0.5325, 0.5553, 0.4856, 0.4419,\n",
       "         0.5109, 0.4989, 0.4879, 0.5516, 0.4665, 0.4885],\n",
       "        [0.4313, 0.5107, 0.4647, 0.5070, 0.3734, 0.5325, 0.5094, 0.5313, 0.4952,\n",
       "         0.5050, 0.5053, 0.4582, 0.5098, 0.4935, 0.5422, 0.5508, 0.4754, 0.4621,\n",
       "         0.5147, 0.4963, 0.4904, 0.5518, 0.4919, 0.4837],\n",
       "        [0.4287, 0.5183, 0.4771, 0.5102, 0.3620, 0.5300, 0.5104, 0.5252, 0.5028,\n",
       "         0.5097, 0.5025, 0.4503, 0.5194, 0.4983, 0.5644, 0.5604, 0.4889, 0.4741,\n",
       "         0.5083, 0.4860, 0.4742, 0.5409, 0.4789, 0.4811],\n",
       "        [0.4292, 0.5113, 0.4729, 0.5150, 0.3684, 0.5277, 0.5236, 0.5301, 0.4960,\n",
       "         0.4985, 0.5028, 0.4697, 0.5121, 0.4887, 0.5604, 0.5585, 0.4972, 0.4733,\n",
       "         0.5273, 0.4884, 0.4994, 0.5463, 0.4716, 0.4842],\n",
       "        [0.4315, 0.5094, 0.4581, 0.5189, 0.3860, 0.5267, 0.5070, 0.5283, 0.5018,\n",
       "         0.4953, 0.4946, 0.4584, 0.5242, 0.4804, 0.5432, 0.5563, 0.4895, 0.4688,\n",
       "         0.5118, 0.4794, 0.4857, 0.5507, 0.4909, 0.4903]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6868, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(predictions, sample_batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"toxic-comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "  logger=logger,\n",
    "  callbacks=[early_stopping_callback,checkpoint_callback],\n",
    "  max_epochs=N_EPOCHS,\n",
    "  gpus=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | bert       | BertModel | 105 M \n",
      "1 | classifier | Linear    | 18.5 K\n",
      "2 | criterion  | BCELoss   | 0     \n",
      "-----------------------------------------\n",
      "105 M     Trainable params\n",
      "0         Non-trainable params\n",
      "105 M     Total params\n",
      "421.051   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe3ca26e0bc434a87d2f8a04920833a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1600: PossibleUserWarning: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db5637472a643eca6aba3a77c5d4b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
