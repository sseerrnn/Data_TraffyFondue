{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import CamembertTokenizerFast,AutoModel,AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.transformers import generate_signature_output\n",
    "import mlflow\n",
    "from torch import nn\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('multilabel.pth',map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "BERT_MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "# model = AutoModel.from_pretrained('multilable_pretrained')\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(text):\n",
    "#     input = tokenizer(text,padding='max_length', max_length = 256, truncation=True,return_tensors=\"pt\")\n",
    "#     input = input['input_ids']\n",
    "#     output = model(input).logits\n",
    "#     # output = F.sigmoid(output)\n",
    "    \n",
    "    \n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('multilabel_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained('multilabel_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(25005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "# mlflow.set_experiment('multilabel')\n",
    "# with mlflow.start_run() as run:\n",
    "#     mlflow.pytorch.save_model(model,'multilabel')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OverRide output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define your model architecture here\n",
    "        self.model = torch.load('multilabel.pth',map_location=torch.device('cpu'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass of your model\n",
    "        # This function will be used during training, not for prediction\n",
    "        # Typically, you would define the layers and operations here\n",
    "        \n",
    "        return self.model(x).logits\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8791,  0.3273, -7.1046, -6.1185, -6.3318,  3.3170, -5.5375, -7.7529,\n",
       "         -8.0882, -7.0107, -8.0564, -8.9456, -7.5059, -8.0857, -6.1525, -7.6930,\n",
       "         -7.5997, -8.0280, -8.2484, -8.6904, -7.5230, -7.6227, -8.2611, -9.7334]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8791,  0.3273, -7.1046, -6.1185, -6.3318,  3.3170, -5.5375, -7.7529,\n",
       "         -8.0882, -7.0107, -8.0564, -8.9456, -7.5059, -8.0857, -6.1525, -7.6930,\n",
       "         -7.5997, -8.0280, -8.2484, -8.6904, -7.5230, -7.6227, -8.2611, -9.7334]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output =  generate_signature_output(model,X.numpy())\n",
    "signature = infer_signature(X.numpy(), model.predict(X).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): CamembertForSequenceClassification(\n",
       "    (roberta): CamembertModel(\n",
       "      (embeddings): CamembertEmbeddings(\n",
       "        (word_embeddings): Embedding(25005, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): CamembertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): CamembertClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "mlflow.set_experiment('multilabel')\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pytorch.log_model(model, \"model\",signature=signature)\n",
    "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8791,  0.3273, -7.1046, -6.1185, -6.3318,  3.3170, -5.5375, -7.7529,\n",
       "         -8.0882, -7.0107, -8.0564, -8.9456, -7.5059, -8.0857, -6.1525, -7.6930,\n",
       "         -7.5997, -8.0280, -8.2484, -8.6904, -7.5230, -7.6227, -8.2611, -9.7334]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_json(server_url, input_json):\n",
    "    response = requests.post(server_url, json=input_json)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Request failed with status code: %s, response: %s\"\n",
    "                        % (response.status_code, response.text))\n",
    "    \n",
    "def predict(server_url, text):\n",
    "    inputs = tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']\n",
    "    # print(inputs)\n",
    "    data = {\"inputs\":inputs.numpy().tolist()}\n",
    "    # print(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predict_json(server_url, data)\n",
    "\n",
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "\n",
    "predict_result = predict(\"http://127.0.0.1:1244/invocations\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[-2.8791043758392334,\n",
       "   0.3272898197174072,\n",
       "   -7.104610919952393,\n",
       "   -6.118514537811279,\n",
       "   -6.331795692443848,\n",
       "   3.317025661468506,\n",
       "   -5.537487983703613,\n",
       "   -7.752892971038818,\n",
       "   -8.088247299194336,\n",
       "   -7.010658264160156,\n",
       "   -8.05642318725586,\n",
       "   -8.945622444152832,\n",
       "   -7.5058794021606445,\n",
       "   -8.085744857788086,\n",
       "   -6.152515411376953,\n",
       "   -7.692965507507324,\n",
       "   -7.599690914154053,\n",
       "   -8.028019905090332,\n",
       "   -8.24844741821289,\n",
       "   -8.690380096435547,\n",
       "   -7.523009777069092,\n",
       "   -7.622708320617676,\n",
       "   -8.261131286621094,\n",
       "   -9.733368873596191]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['ถนน','ทางเท้า','แสงสว่าง','ความปลอดภัย','น้ำท่วม','ความสะอาด','กีดขวาง',\n",
    "        'ท่อระบายน้ำ','สะพาน','จราจร','สายไฟ','คลอง','เสียงรบกวน','ต้นไม้','ร้องเรียน',\n",
    "        'ป้าย','สัตว์จรจัด',\"PM25\",'สอบถาม','เสนอแนะ','คนจรจัด','การเดินทาง','ห้องน้ำ','ป้ายจราจร']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_prediction(predict_result):\n",
    "    y_pred = []\n",
    "    res = np.array(predict_result['predictions'])\n",
    "    res = torch.tensor(res)\n",
    "    res = F.sigmoid(res)\n",
    "    for row in res:\n",
    "        y_pred.append([1 if i>=0.5 else 0 for i in row])\n",
    "\n",
    "    y_pred_decoded = []\n",
    "    for i in y_pred:\n",
    "        tmp = []\n",
    "        for c in range(len(i)):\n",
    "            if(i[c]==1):\n",
    "                tmp.append(types[c])\n",
    "        y_pred_decoded.append(tmp)\n",
    "\n",
    "    return y_pred_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ทางเท้า', 'ความสะอาด']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_prediction(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('multilabel_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "\n",
    "\n",
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "    def preprocess(self, inputs):\n",
    "        return self.tokenizer(inputs, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']\n",
    "        \n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        return self.model(model_inputs)\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        return model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MyPipeline(model = model,tokenizer = tokenizer,task = \"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.transformers import generate_signature_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from mlflow.models.signature import ModelSignature\n",
    "# from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "# input_schema = Schema(\n",
    "#     [\n",
    "#         TensorSpec(np.dtype(np.int64), (1,256)),\n",
    "#     ]\n",
    "# )\n",
    "# output_schema = Schema([TensorSpec(np.dtype(np.float32), (1, 24))])\n",
    "# signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput([('logits',\n",
       "              tensor([[-2.8791,  0.3273, -7.1046, -6.1185, -6.3318,  3.3170, -5.5375, -7.7529,\n",
       "                       -8.0882, -7.0107, -8.0564, -8.9456, -7.5059, -8.0857, -6.1525, -7.6930,\n",
       "                       -7.5997, -8.0280, -8.2484, -8.6904, -7.5230, -7.6227, -8.2611, -9.7334]]))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = CamembertTokenizerFast.from_pretrained(BERT_MODEL_NAME, padding='max_length', max_length=256, truncation=True, return_tensors='pt')\n",
    "# tokenizer.padding = 'max_length'  # Pad sequences to the maximum length\n",
    "# tokenizer.max_length = 256  # Set the maximum sequence length\n",
    "# tokenizer.truncation = True \n",
    "# tokenizer('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า', padding='max_length', max_length=256, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(tokenizer('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า', padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sern7\\AppData\\Local\\Temp\\ipykernel_19388\\4265276266.py:11: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  mlflow.transformers.log_model(\n",
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\mlflow\\models\\model.py:553: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "2023/05/18 12:41:01 WARNING mlflow.transformers: The model card could not be retrieved from the hub due to [Errno 13] Permission denied: 'multilabel_pretrained'\n",
      "2023/05/18 12:41:01 WARNING mlflow.transformers: An unsupported Pipeline type was supplied for signature inference. Either provide an `input_example` or generate a signature manually via `infer_signature` if you would like to have a signature recorded in the MLmodel file.\n",
      "C:\\Users\\sern7\\AppData\\Local\\Temp\\ipykernel_19388\\4265276266.py:18: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  loaded = mlflow.transformers.load_model(model_uri)\n",
      "2023/05/18 12:41:26 INFO mlflow.transformers: 'runs:/902d963ffe684c39afd6d45c496ee8e0/multilabel_pipeline' resolved as 'mlflow-artifacts:/166719102482155102/902d963ffe684c39afd6d45c496ee8e0/artifacts/multilabel_pipeline'\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x25e7d41e990>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "mlflow.set_experiment('multilabel_model')\n",
    "# mlflow.transformers.autolog()\n",
    "with mlflow.start_run() as run:\n",
    "    # mlflow.transformers.save_model(\n",
    "    #     transformers_model=pipeline,\n",
    "    #     path=\"transformer_pipeline\",\n",
    "    # )\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model=pipeline,\n",
    "        artifact_path=\"multilabel_pipeline\",\n",
    "        \n",
    "    )\n",
    "model_uri = \"runs:/{}/multilabel_pipeline\".format(run.info.run_id)\n",
    "\n",
    "loaded = mlflow.transformers.load_model(model_uri)\n",
    "loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_5', 'score': 0.9974890947341919}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.transformers import generate_signature_output\n",
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "df = pd.DataFrame([text],columns=['text'])\n",
    "output =  generate_signature_output(loaded,df)\n",
    "signature = infer_signature(df, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sern7\\AppData\\Local\\Temp\\ipykernel_19388\\797863787.py:1: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  mlflow.transformers.save_model(\n",
      "2023/05/18 12:41:29 WARNING mlflow.transformers: The model card could not be retrieved from the hub due to [Errno 13] Permission denied: 'C:\\\\Users\\\\sern7\\\\AppData\\\\Local\\\\Temp\\\\tmpeytkukox\\\\multilabel_pipeline\\\\pipeline'\n",
      "C:\\Users\\sern7\\AppData\\Local\\Temp\\ipykernel_19388\\797863787.py:8: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  loaded = mlflow.transformers.load_model(\"text-class\")\n"
     ]
    }
   ],
   "source": [
    "mlflow.transformers.save_model(\n",
    "    transformers_model=loaded ,\n",
    "    path=\"text-class\",\n",
    "    signature=signature,\n",
    "    input_example=df,\n",
    ")\n",
    "\n",
    "loaded = mlflow.transformers.load_model(\"text-class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sern7\\AppData\\Local\\Temp\\ipykernel_19388\\3407490784.py:1: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  mlflow.transformers.log_model(\n",
      "c:\\Users\\sern7\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\mlflow\\models\\model.py:553: FutureWarning: The 'transformers' MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.28.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "2023/05/18 12:41:36 WARNING mlflow.transformers: The model card could not be retrieved from the hub due to [Errno 13] Permission denied: 'D:\\\\CU\\\\Y3T2\\\\DS\\\\Data_TraffyFondue\\\\text-class\\\\pipeline'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x25e0ea0a450>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.transformers.log_model(\n",
    "        transformers_model=loaded,\n",
    "        artifact_path=\"multilabel_pipeline\",\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow.pytorch\n",
    "# import mlflow\n",
    "# mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "# mlflow.set_experiment('multilabel-experiment')\n",
    "# with mlflow.start_run() as run:\n",
    "#     mlflow.pytorch.log_model(model, \"model\")\n",
    "# model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
    "# model = mlflow.pytorch.load_model(model_uri)\n",
    "# model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "BERT_MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input  = tokenizer.encode_plus(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.8791,  0.3273, -7.1046, -6.1185, -6.3318,  3.3170, -5.5375, -7.7529,\n",
       "         -8.0882, -7.0107, -8.0564, -8.9456, -7.5059, -8.0857, -6.1525, -7.6930,\n",
       "         -7.5997, -8.0280, -8.2484, -8.6904, -7.5230, -7.6227, -8.2611, -9.7334]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(encoded_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataframe_split': {'index': [0], 'columns': ['text'], 'data': [['ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า']]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': 'LABEL_5'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_json(server_url, input_json):\n",
    "    response = requests.post(server_url, json=input_json)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Request failed with status code: %s, response: %s\"\n",
    "                        % (response.status_code, response.text))\n",
    "    \n",
    "def predict(server_url, df):\n",
    "    data = {\"dataframe_split\": df.to_dict(orient='split')}\n",
    "    print(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predict_json(server_url, data)\n",
    "\n",
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "\n",
    "# def predict(text):\n",
    "#     input = tokenizer(text,padding='max_length', max_length = 256, truncation=True,return_tensors=\"pt\")\n",
    "#     input = input['input_ids'].squeeze(1).to(device)\n",
    "#     output = model(input).logits\n",
    "#     output = F.sigmoid(output)\n",
    "#     res = output.detach().cpu().numpy()\n",
    "    \n",
    "#     return output\n",
    "\n",
    "predict(\"http://127.0.0.1:1245/invocations\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataframe_split': {'index': [0], 'columns': ['text'], 'data': [['ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า']]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': 'LABEL_5'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"http://127.0.0.1:1245/invocations\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
